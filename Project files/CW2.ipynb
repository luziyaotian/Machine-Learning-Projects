{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  COMP24112 Lab 2: News Article Classification by k-NN\n",
    "\n",
    "## 1. Task description\n",
    "\n",
    "You will work on a news article classification task.\n",
    "The provided dataset includes a total of 800 articles taken from Reuters newswire.\n",
    "They belong to 4 classes: \"earn\" (0), \"crude\" (1), \"trade\" (2) and \"interest\" (3).\n",
    "There are 200 articles per class.\n",
    "Each article is characterised by word occurrences.\n",
    "The list of used words is called a vocabulary.\n",
    "In our dataset, the vocabulary includes a total of 6428 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "\n",
    "First we need to import the data.\n",
    "Run the below cell to load the data using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "\n",
    "data, labels, class_names, vocabulary = np.load(\"ReutersNews_4Classes_sparse.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Sparsity\n",
    "\n",
    "Most documents only contain a small subset of the vocabulary, resulting in a very sparse data matrix.\n",
    "To handle the sparsity, in this exercise `data` is represented as a `scipy.sparse.csr_matrix`, which can store sparse matrices efficiently while still allowing efficient row-based indexing.\n",
    "You can learn more about `csr_matrix` and other ways of dealing with sparse matrices at https://docs.scipy.org/doc/scipy/reference/sparse.html.\n",
    "\n",
    "Note, however, that `data` is **not** a normal NumPy array.\n",
    "While most operations will be the same as with a normal dense array, **you cannot use a sparse matrix to index another matrix**.\n",
    "If you need to do this, either first convert the matrix to a NumPy array with the `toarray()` method, or use methods specifically designed to work with sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t3\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 21)\t2\n",
      "  (0, 24)\t1\n",
      "  (0, 105)\t1\n",
      "  (0, 127)\t1\n",
      "  (0, 227)\t1\n",
      "  (0, 275)\t1\n",
      "  (0, 334)\t2\n",
      "  (0, 341)\t1\n",
      "  (0, 348)\t1\n",
      "  (0, 359)\t1\n",
      "  (0, 411)\t1\n",
      "  (0, 426)\t1\n",
      "  (0, 1428)\t1\n",
      "  (0, 2058)\t1\n",
      "  (0, 5555)\t1\n",
      "[[0 0 1 ... 0 0 0]]\n",
      "['share' 'split' 'say' 'two-for-one' 'shareholder' 'annual' 'meeting'\n",
      " 'reuter' 'ct' 'note' 'company' 'pay' 'subject' 'increase' 'stock'\n",
      " 'dividend' 'april' 'northern' 'declare' 'approval' 'telecom' 'post-split'\n",
      " 'nt']\n"
     ]
    }
   ],
   "source": [
    "print(data[41,:]) # A sparse row vector; the output will be the non-zero indices and their values.\n",
    "print(data[41,:].toarray()) # Convert back to a NumPy array. Note that the result is a (1, 6428) matrix, not a vector.\n",
    "# print(vocabulary[data[41,:] > 0]) # Can't index vocabulary with a sparse matrix.\n",
    "rows, columns, values = scipy.sparse.find(data[41,:]) # Find the non-zero entries in the 42nd document.\n",
    "print(vocabulary[columns]) # Prints the words present in the 42nd document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full vocabulary, you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "island, telephone, share, split, approve, say, previously, announce, two-for-one, common, shareholder, annual, meeting, reuter, year, net, shr, loss, nil, vs, profit, ct, rev, mln, note, current, include, charge, discontinue, operation, dlr, ec, state, tax, majority, european, community, member, strong, reservation, import, domestically-produced, oil, fat, propose, commission, senior, diplomat, special, committee, agricultural, expert, voice, objection, measure, prepare, ground, farm, begin, monday, add, france, italy, indicate, support, proposal, lead, initially, tonne, 1987/88, price, round, complete, sale, french, unit, business, compagnie, francaise, group, investor, employee, minnesota, disclose, term, deal, plan, asset, electronic, shoe, town, end, jan, respectively, december, wisconsin, fwb, buy, bank, corp, acquire, bancshare, cash, acquisition, hold, company, total, billion, purchase, time, earning, office, paul, area, american, product, 3rd, qtr, period, feb, mth, avg, 4th, seven, entertainment, publication, disposal, pay, store, correct, mobil, mob, upgrade, refinery, spend, texas, catalytic, convert, component, gasoline, use, super, unleaded, allow, continuous, basis, shutdown, currently, shut, twice, produce, barrel, day, construction, start, late, completion, set, output, inc., result, slightly, ab, weakening, dollar, cause, drop, chief, executive, good, final, report, release, earlier, allocation, crown, compare, despite, fall, industrial, high, car, truck, completely, sell, year-end, operate, income, financial, strength, exceptional, opportunity, invest, future, meridian, energy, letter, intent, development, privately-held, decide, terminate, exclude, quarter, extraordinary, gain, british, minister, discuss, public, spending, finance, need, control, talk, today, chancellor, exchequer, nigel, lawson, treasury, spokesman, review, economy, domestic, decline, comment, subject, concerted, action, arise, u., currency, dip, sharply, week, month, relative, stability, agreement, major, industrialised, nation, paris, february, stabilise, feed, heller, urge, broad, reform, aid, banking, federal, reserve, board, governor, robert, strengthen, permit, formation, service, involve, like, insurance, real, estate, security, speech, delivery, new, york, analyst, association, believe, increase, diversification, line, key, idea, advocate, regulation, various, thrift, investment, subsidiary, handle, limit, place, extension, credit, associate, institution, transaction, necessary, avoid, abuse, position, require, serve, make, commitment, maintain, capital, word, fail, long, positive, commercial, enterprise, provision, flow, effect, corporation, customer, deposit, assure, incentive, remove, access, national, international, united, mean, steady, america, world, table, competitive, department, qtly, div, pct, 2-for-1, stock, cie, advance, science, datum, available, raise, dividend, quarterly, form, ask, number, payable, pre-split, april, record, distribute, receive, commonwealth, settlement, debt, stockholder, california, concern, title, northern, county, costa, san, home, saving, initial, cotton, u.s., run, season, census, bureau, brand, bp, manage, director, hike, standard, offer, user, merger, pacific, union, processing, mutually, agree, withdraw, negotiation, sign, merge, november, continue, ownership, commit, additional, history, expect, after-tax, close, primarily, direct, mail, marketing, likely, meet, growth, goal, lose, industry, regular, payout, declare, class, equal, prior, manufacturing, paper, dunn, jame, river, partly, reduce, contingent, payment, offset, closing, approval, satisfactory, labor, old, republic, int'l, june, crn, money, market, mutual, fund, expectation, value, petroleum, plc, half, signal, patch, think, bid, clear, confidence, higher, sanford, margosh, shearson, lehman, brother, early, tender, opec, win, war, crack, bruce, huge, implication, rest, issue, particularly, target, mention, usx, court, draw, attention, australian, holme, rumor, foresee, firm, takeover, situation, exception, possibly, partner, ago, restructure, point, rally, response, exxon, xon, rise, 1-1/8, chevron, chv, jump, texaco, tx, climb, 1/4, unocal, ucl, 1-3/4, occidental, amoco, 6-1/4, heavy, trading, session, wall, speculate, boost, 2-1/4, fact, giant, change, outlook, stay, hasty, view, look, long-term, heart, exceed, benchmark, crude, west, intermediate, trade, able, bright, alaskan, prudhoe, bay, field, north, extremely, attractive, large, just, fit, dean, witter, eugene, ahead, government, u.k., dispose, way, unite, revenue, cable, acre, co., finalize, bancorp, universal, holding, contract, obligation, chairman, freedom, recognize, first-quarter, defer, complex, recognition, come, repayment, loan, grant, commerce, house, dec, investigate, assurance, succeed, experience, negative, waiver, marine, midland, working, guarantee, secure, substantially, bernard, president, act, officer, engineering, halt, software, shipment, temporarily, technical, problem, program, anticipate, resume, fourth, oper, adjust, reverse, october, fair, lane, right, realty, research, backlog, cardena, decision, jorge, manager, colombia, coffee, federation, important, emerge, upcoming, organization, london, march, council, export, quota, routine, happen, unlikely, tell, journalist, suspend, failure, colombian, reporter, weekly, brazil, far, apart, prompt, yesterday, policy, know, project, stockpile, level, producer, accord, statistic, shortfall, regulatory, agency, 1st, earn, year-ago, tobacco, strike, introduce, low-priced, cigarette, performance, operating, trader, soviet, sugar, raw, night, hand, discount, spot, source, japanese, cargo, thai, relatively, nearby, remain, sharp, help, provoke, cover, cent, pound, limited, trust, date, proceed, hilton, holder, cease, liquidate, worth, debenture, substitute, distribution, connection, represent, balance, satisfy, liability, second, vote, profitable, follow, specific, figure, definitely, news, amendment, certificate, relate, center, property, plastic, work, denis, consumer, delegate, formally, present, friday, widespread, outstanding, item, reach, bilateral, consultation, delegation, main, draft, rule, package, certain, want, discussion, differential, different, origin, forward, material, minor, modification, original, intend, single, candidate, post, coast, exist, gmt, management, pledge, provide, expand, base, combustion, csp, environmental, principle, e.c, jordan, privately, pom, potomac, electric, power, virginia, territory, mainly, low, margin, cost, enter, head, design, manufacture, restructuring, adversely, affect, realize, significant, expense, remainder, pact, ohio, wholly, warrant, creditor, thing, micro, device, develop, chip, gate, complexity, harden, n.y, book, acceptance, nationally, schedule, borrowing, city, borrow, wednesday, two-week, statement, assumption, preferred, reorganization, resource, equivalent, previous, 3-for-2, effective, entitle, arsenal, determine, small, fiscal, attribute, pressure, cut, gross, addition, incur, aim, productivity, undertake, extend, hour, salary, job, save, annually, care, supply, average, free, depressed, seasonally, revise, economist, poll, forecast, forgiveness, dealer, collapse, foreign, exchange, speculation, germany, big, crash, stand, damage, claim, case, seek, mark, accuse, manipulate, private, great, recently, appeal, people, medical, evidence, life, crucial, hernandez, arturo, grisanti, regional, exporter, critical, effort, achieve, recovery, stabilize, non-opec, danger, reversal, really, movement, depend, venezuela, speak, opening, fifth, ministerial, informal, latin, caribbean, ecuador, mexico, attend, conference, observer, combat, congress, jaime, lusinchi, miraflore, presidential, palace, javi, espinosa, jose, assistant, secretary, perry, rubio, howard, b., significantly, inventory, potential, possible, shift, demand, brazilian, natural, gas, production, petrobras, basin, country, bpd, consumption, derivative, fuel, medium, general, central, three-for-two, white, semiconductor, economic, recommendation, reagan, retaliate, japan, alleged, unfair, practice, official, retaliation, curb, impose, senate, unanimously, penality, hard, hit, summer, stop, dump, open, return, anti-dumping, duty, semiconductors., indiana, plant, stake, chicago, banker, sec, try, gold, study, recommend, water, license, arrangement, appropriate, financing, estimate, feasibility, canadian, short, yield, rate, probable, ore, grade, yearly, break, zone, considerable, red, lake, mp, coal, related, nominal, consideration, specify, alberta, michael, retain, unspecified, royalty, reclamation, expire, reclaim, activity, occur, principal, authorize, proposed, article, option, broaden, multinational, sweden, variety, instead, optimistic, grow, leadership, intelligence, defense, congressional, joint, improve, worker, attitude, equipment, account, adopt, bring, apparent, solution, immediate, lack, appear, count, n't, marshall, goldman, harvard, university, hearing, fast, step, similar, peter, institute, advanced, commodity, discourage, innovation, technological, resistance, overall, surface, massive, party, complain, carry, conflict, quality, predict, technology, microprocessor, allowance, writedown, preliminary, finding, conduct, examination, authority, adjustment, deplete, environment, improvement, near, portfolio, non-performing, marathon, macmillan, ctc, ontario, ruling, uphold, block, hear, alfre, david, leave, join, motion, restate, reflect, january, delay, force, sheet, omaha, writeoff, subordinated, gatt, warn, budget, protectionism, emphasis, deficit, misplace, lie, agreeement, tariff, stress, protectionist, threaten, fundamental, size, remedie, encourage, personal, percentage, washington, resist, macroeconomic, barrier, little, reduction, inflation, basic, combination, insufficient, excessive, expansion, slow, workforce, risk, loom, imbalance, explanation, prediction, realignment, bear, sizeable, combined, impact, rapidly, worsen, climate, uncertainty, push, turn, trade., surprising, depreciation, expensive, suggest, idle, human, underutilised, factory, gear, abroad, stagnant, pattern, sector, decade, moderately, indebted, chile, philippine, south, korea, thailand, smelter, northw, mid-may, capacity, lease, corp., reopen, successful, unchanged, index, consecutive, year-on-year, september, winter, clothing, vegetable, electricity, housing, education, footwear, unadjusted, tokyo, food, utility, n.z, zealand, statistical, panel, sanction, violation, u.s.-japanese, administration, announcement, frustration, probably, consult, aide, persuade, abide, july, govern, u.s.-made, dumping, closed, unanimous, penalty, contain, semiconductor-based, television, video, cassette, recorder, nakasone, visit, prime, yasuhiro, week-long, cabinet, masaharu, gotoda, resolve, friction, venice, summit, western, democracy, tadashi, kuranari, accompany, ministry, violate, microchip, asia, australia, bp.l, compensation, subsidy, refiner, partially, enable, modest, pre-tax, pct-owned, sustain, exploration, endeavour, 33-1/3, chemical, maker, farmer, finalise, nitrogen, anz, jardine, h.k, turnover, bonus, par, august, broken, hill, pty, brkn., minority, mineral, steel, corporate, adjusted, finish, machine, tape, machinery, downturn, planning, gnp, match, balanced, four-for-one, ordinary, quote, simon, section, especially, hong, kong, land, fleming, lower, reorganisation, strain, flexibility, recent, pende, exercise, nearly, transfer, hk, strategic, spin, dairy, plus, cross, transform, middle, east, weakness, strategy, structure, policy., create, midday, rumour, 1985/86, range, register, qualify, tax-free, introduction, imputation, rank, influence, legislation, confine, division, generally, volume, bass, strait, operational, difficulty, largely, iron, southern, cement, acreage, surplus, lobby, agriculture, usda, taiwan, fulfil, protest, award, dominican, taiwanese, list, badly, lay, staff, entire, container, ship, cancel, local, press, later, file, protection, law, china, morning, charle, comprise, singapore, manila, seoul, osaka, provisional, survey, 1986/87, certainly, long-standing, reason, peso, ready, throw, submit, corazon, aquino, wait, election, enjoy, drive, longer, region, learn, mistake, diversify, corn, farming, cloth, lesson, diversified, industry., room, renewal, write, revive, subsidise, markets., uneconomical, bullish, artificial, happy, supplier, restore, watch, slash, suit, danish, cooperative, yen, anger, telecom, dispute, equity, telecommunication, legal, telecommunications, send, postal, malcolm, baldrige, object, participation, express, oppose, role, dampen, opposition, compete, monopoly, wireless, cawl.l, ford, motor, citibank, na, cci, digital, communication, merrill, lynch, mer, competitor, reject, argue, precedent, channel, dilute, eventually, bache, political, leverage, wo, diplomatic, reasonable, sort, watanabe, keidanren, arrange, outline, thursday, newspaper, britain, apply, placement, participate, wake, spark, herald, subsequent, one-for-four, radio, station, belgian, parent, metal, link, appreciation, defence, document, defend, itself, stg, pretax, u.k, england, shortage, factor, liquidity, mature, drain, aluminium, smelt, past, cheap, primary, indonesia, calendar, tight, recover, weak, dominate, segment, passenger, light, vehicle, suffer, profitability, erode, lift, penetration, buyer, netherland, ban, suspect, foot, mouth, daniel, notify, km, northeast, province, immediately, milk, beef, alternative, canada, al, swap, deputy, jeremy, davis, broadly, nz, overseas, closer, relation, treaty, accept, normally, invite, consolidated, attributable, franc, priority, ag, anticipated, mass, dieter, satisfied, 1984/85, projection, employ, barber, conable, sake, contribution, businessman, academic, support., assist, road, bridge, infrastructure, advantage, rechannelle, notably, india, faster, developed, concessionary, lending, affiliate, ida, reconstruction, ibrd, structural, competition, maybe, und, refine, concentrate, core, five-year, convertible, redeemable, spain, assistance, daily, oblige, borrower, window, normal, overnight, suspension, 10-day, accounting, requirement, peseta, hard-pressed, soothe, defuse, mount, chance, success, slim, box, powerful, ronald, congressman, coincide, retaliatory, live, arm, separate, pep, sagge, short-term, redirect, away, over-dependence, infighting, rob, punch, prevent, insist, pass, parliament, fear, tacit, admission, inadequate, hope, quick, passage, trip, shatter, parliamentary, boycott, face, possibility, virtually, empty-handed, order, liberal, democratic, ldp, deregulation, benefit, accelerate, portion, democrat-controlled, complement, longer-term, high-ranking, advisory, body, haruo, maekawa, concrete, follow-up, potentially, politically, explosive, explicit, reality, subcommittee, consider, undergo, amounte, gradual, outright, band, 9-13/16, intervene, dealing, intervention, aggressive, selling, ease, bundesbank, touch, test, fairly, contrast, progressive, launch, supermarket, minimum, one-for-one, debate, lately, buying, programme, highlight, worldwide, destination, turkey, libya, worthwhile, enquiry, proportion, operator, tighten, considerably, eastern, react, upwards, physical, interim, pakistan, shortly, originally, tomorrow, egypt, arrival, greece, internal, sa, mining, sum, elaborate, societe, countertrade, gap, search, non-communist, conserve, wheat, tea, jute, impetus, stc, mmtc, respect, bulk, promote, indian, spokeswoman, targette, bloc, non-convertible, rupee, textile, narrow, insignificant, shrink, dynamism, discreetly, officially, bartering, yugoslavia, rail, global, clause, preference, kind, flexible, quietly, interested, aircraft, drill, rig, railway, illustrate, korean, drilling, platform, state-run, wholesale, 2nd, carryforward, wage, one-third, transportation, responsible, fish, drug, apparel, spring, merchandise, man, mmb, weather, disrupt, sea, shipping, saturday, rain, wind, tonight, frequent, southwest, northwest, wave, build, diminish, weekend, suez, lloyd, port, chamber, monthly, expected, german, so-called, grey, illegal, pose, hedge, dollar-denominated, third-party, centre, swiftly, mohamme, keen, contentious, concession, question, prove, assign, soon, fully, advise, yr, closely, st., mortgage, servicing, combine, origination, afternoon, austria, austrian, deny, suggestion, vienna, creditanstalt, girozentrale, aware, purely, purpose, han, obtain, application, process, procedure, facility, equally, non-recurring, revaluation, offering, restaurant, manhattan, headquarters, sept, distributor, manufacturer, family, trend, fee, analyze, double, dougla, moderate, particular, vice, identify, it., focus, broadcasting, electrical, consistently, poor, w., establish, expenditure, fine, smoke, condition, quickly, uk, revoke, licence, select, progress, ca, yes, cross-section, influential, increasingly, impatient, sense, urgency, undermine, margaret, thatcher, hesitate, reciprocal, clearly, mind, defict, coordinate, restrictive, feeling, inside, parliamentarian, conservative, refuse, authorise, london-based, legally-binding, channon, engage, collective, alan, clark, interview, certification, overnight., reciprocity, regard, visible, dominant, aspect, fairness., minimise, indication, weigh, wide, retail, building, course, prospect, temporary, indirectly, repurchase, 6-1/8, sydney, ltd., appliance, retroactively, capitalize, intangible, ability, ongoing, waste, removal, mar, outlet, promotional, information, des, nec, pricing, jerome, cornerstone, qtrly, contingency, drawing, fixed, zero, malaysian, malaysia, conclude, unable, implement, organize, assess, sun, publishing, publish, lewis, glamis, glgvf, rebound, florida, mile, offshore, louisiana, gulf, discovery, depth, sand, cubic, choke, owner, venture, oklahoma, slap, receiver, laser-printer, penalize, hitachi, toshiba, fujitsu, reaan, invoke, negotiator, extensive, avail, peg, intention, tuesday, spur, belief, repeat, switch, cargill, echo, warehouse, pick, tab, storage, stipulate, mandatory, disagree, lot, 'll, outside, walter, brown, verify, gather, caution, opinion, difference, pretty, plaza, travel, gro, francisco, 109-billion, rat, lawsuit, dilson, funaro, monetary, imf, carefully, space, post-split, soft, type, slump, tie, network, bond, imperial, tangible, pace, constructive, steam, pronounced, william, reynold, upward, volatile, picture, competitiveness, willing, tolerate, s.g, warburg, door, conclusion, reaffirm, n.a., pursue, adviser, instruct, grain, status, satellite, choose, battle, team, dutch, philip, sit, ally, df, 13-1/2, amid, chinese, engineer, underway, slide, scale, premium, fix, nigeria, weight, minstar, confirm, restrict, maximum, welcome, conform, ring, exclusively, dollar-based, conversion, sterling, alleviate, romania, attract, active, zinc, replace, difficult, totally, disappear, feature, volatility, presently, squeeze, deliver, widen, declaration, 25th, narrowly, notice, resident, charter, glass, dynamic, michigan, den, stage, liquid, seasonal, premi, relax, relaxation, surge, framework, emergency, professor, bit, liberalisation, end-february, angrily, allegedly, eiaj, shoichi, saba, premature, irrational, attempt, assessment, comply, agreement., governmental, reconsider, evaluate, objective, emotional, bias, heated, cut-price, american-made, salvage, multi-lateral, organisation, regret, tree, licensing, bulletin, arab, establishment, preserve, civil, devastate, productive, acceptable, meantime, protect, health, accession, postpone, scrap, abolish, evolution, foreigner, widely, wang, trouble, suitable, unacceptable, sound, conciliatory, bitter, row, explain, stance, thoroughly, kyodo, high-level, settle, formal, request, deadline, u.s./japan, investigation, asian, hammer, distinctly, hajime, tamura, miti, downplay, significance, remark, message, urgently, admit, geneva-based, police, legality, wishful, thinking, confident, unregulated, dry, acknowledge, ensure, tsba.t, likewise, islamic, idb, porfolio, redeem, emirate, wam, cooperation, gcc, bahrain, kuwait, oman, qatar, saudi, arabia, uae, restrain, mid-1986, boom, recession, fresh, coordination, quite, substantial, series, examine, kuwaiti, dinar, trade-weighted, theory, foster, stable, instrument, recognise, hamper, premier, three-year, vice-chairman, banque, morgan, guaranty, treasurer, bad, plunge, economically, brief, pave, soar, dictate, erupt, full-scale, adverse, relationship, isolate, fall-out, sure, perception, respond, that., spread, depict, severe, warning, belligerent, angry, walk, secret, draconian, enforce, irrational., meaningless., solve, convince, allegation, fuer, gemeinwirtschaft, bkfg.f, prospectus, turbulence, troubled, depress, compensate, emphasise, necessarily, debtor, deutsche, sumita, satoshi, beginning, careful, judgement, septemb, steep, stem, peru, garcia, jungle, ecuadorean, border, site, treatment, extract, u.s.-japan, refer, spare, sides., understand, all., observe, adhere, avert, hop, tone, auto, ignore, bidding, partnership, afg, reiterate, negotiate, conglomerate, fetch, inform, explore, prefer, green, correspond, george, cumulative, tropical, woolworth, indonesian, suharto, backdrop, devalue, rupiah, editorial, jakarta, deregulate, non-oil, steadily, burden, end-investor, cautious, coupon, 10-year, favourably, chain, effect., allege, defiance, non-u., chipmaker, non-regulated, 'm, nick, edward, matsushita, rapid, levy, length, erosion, tom, murtha, capel, altogether, harm, approach, contradiction, hurt, vast, carole, ryavec, salomon, stimulate, export-dependent, economy., luxembourg, deterioration, weaken, deteriorate, provisionally, circumstance, beneficial, moment, unusual, petrochemical, regime, newly, valid, frequently, envisage, 91-day, traditional, afford, allot, differ, underlie, guilde, image, shop, inflow, behalf, easy, comparison, supplement, calculation, cartel, ail, transport, yard, capable, renew, 1988/89, sluggish, favourable, taxation, excess, allocate, guideline, fight, hostile, packaging, swedish, mel, attach, hectare, sixth, healthy, monitor, contemplate, broker, auction, est, client, tour, pioneer, popularity, popular, clearing, sight, threat, lessen, external, commissioner, stabilisation, benefitte, initiative, prepared, modestly, john, organic, maintenance, hotel, end-1986, indirect, sach, berlin, commerzbank, cbkg.f, state-owned, bonn, high-technology, reliance, broadly-based, divide, exciting, method, barclay, independent, subscribe, continued, listing, retire, appoint, refrain, directly, seller, aggressively, grangemouth, explosion, accident, kill, person, hydrocracker, overhaul, african, kenya, flat, interbank, mechanism, chocolate, overhang, pull, doubt, rely, reaction, tool, manoeuvre, perfectly, sensitive, winner, effectively, scheme, sdr, disappoint, nv, surprise, apparently, favour, tate, await, organise, willingness, manner, colorado, coastal, repay, continental, motivate, 7-1/2, million, clarify, actively, gilt, gradually, three-month, fluctuate, bullishness, triton, consist, exploratory, conventional, miller, yugoslav, fso, fluctuation, calculate, belgrade, all-time, cite, automotive, injection, gm, peak, gdp, straight, wood, automobile, custom, texa, windfall, scientific, santa, mexican, petroleos, mexicano, pemex, auditor, arthur, andersen, qualified, subsequently, unisy, uis, newport, geneva, switzerland, pro, element, posted, sulphur, 6-3/8, bow, secondary, principally, seaman, calgary, montreal, mid-april, 're, criterion, formula, master, unitholder, brokerage, divestiture, bob, consistent, non-binding, seattle, contravene, event, highly, incident, reveal, remote, sufficient, outcome, dialogue, matter, agenda, representative, imagine, scheduled, blame, rica, damaging, solidarity, adoption, jopling, portugal, weighted, year-earlier, contribute, pipe, spotlight, congres, rap, enormous, symbol, crisis, symbolize, challenge, nuture, multitude, leader, byrd, democrat, speaker, jim, wright, wide-ranging, readie, dismay, sophisticated, host, citrus, tough, relief, controversial, rep., richard, gephardt, aspirant, missouri, example, mid-1988, tired, 'we, marketplace.', argument, refining, garment, maturity, definitive, merchant, lend, undeveloped, clayton, bt, itt, weakened, improved, netback, mediterranean, pipeline, sweet, sour, alaska, europe, brent, bonny, dubai, cif, iran, cruzado, devaluation, unclear, owe, permanently, golden, don, hughe, hug, execute, detroit, versus, perform, repair, athen, aggregate, silver, king, additionally, dalla, mr, fashion, f.w, roughly, processor, self-imposed, cereal, j.p, belgium, affair, scandal, approximately, jpm, mayfair, hanover, guard, park, alarm, houston, 2-1/2, advisor, heat, decrease, heating, gallon, unemployment, social, usual, arrive, correspondent, gerhard, stoltenberg, karl, otto, poehl, italian, blow, baker, meaningful, 2.0-2.5, repo, permanent, float, translate, patent, disposition, dominion, burlington, n.a, concerned, michel, query, publicly, thoma, unavailable, repeatedly, topic, consume, interesting, essentially, evening, medium-, setback, euromarket, furniture, restriction, sir, lengthy, disadvantage, montedison, spa, agro-industrial, characterize, renato, italiana, interstate, donald, entity, 4-7/8, true, story, play, heavily, fabric, outlay, johnson, enhance, unsuccessful, 5/8, last-ditch, makoto, kuroda, smith, smart, audio, likelihood, monitoring, honor, enforcement, injure, enact, counter, redress, inaccurate, supply-demand, carolina, mellon, marlin, fitzwater, spite, jone, terminal, rent, freddie, beer, guilder, spanish, el, s.a., van, africa, essential, nigerian, successfully, banana, finally, bar, moscow, 12-1/2, samuel, traditionally, shelf, aegean, armed, confrontation, ambassador, nazmi, akiman, greek, reply, turkish, content, reinvest, laser, regulator, criticize, dilution, safety, virtual, responsive, vary, installation, itc, momentum, attain, tranzonic, tnz, iii, atlantic, connect, earthquake, 90-day, iraqi, troop, iranian, iraq, occupy, command, victory, thrust, attack, warplane, tank, baghdad, plane, destroy, raid, shoot, naval, sink, boat, inspection, inspect, administrator, phase, disruption, pilot, airline, assume, realistic, vulnerable, rental, emphasize, escalate, kick, louis, tailor, irna, gholamreza, aqazadeh, manpower, training, exploitation, forum, consequently, slowly, generalize, discipline, restraint, imposition, tend, proved, wilson, stimulus, more., discover, stick, definition, dl, inclusion, one-time, copper, vice-president, consortium, hopeful, cp, historically, streamline, jeffrey, allen, preparation, costly, air, fare, lender, classify, nat'l, spirit, ccc, importer, usa, exclusive, duty-free, locate, wine, compliance, wojnilower, boston, albert, subvert, occasion, harder, justifiably, seriously, participant, hiccup, dress, end-of-fiscal-year, above-average, pick-up, unsustainable, ray, pratt, version, stewart, southeast, fertilizer, exposure, somewhat, ratio, leaseback, distance, strongly, card, nova, scotia, 12-month, survival, bancorporation, implementation, existence, dependent, trim, buoy, magnitude, stanley, volcker, downward, remedy, chase, industrialize, testimony, answer, persistent, worry, ceiling, extent, floor, breakdown, inability, chesebrough, chesebrough-pond, unilever, favorable, said., envision, slight, santo, onshore, oilfield, cast, end-1987, rio, cra, claus, koehler, speculative, separately, hiss, background, dash, let, sentiment, accommodative, surrey, regardless, diametrically, activity., monetarist, concretely, counterpoint, overly, reuter^m, journal, debit, complaint, withdrawal, unless, liquified, rationalisation, swiss, shanghai, ta, hua, modernise, domestically, catch, riyal, spot-next, spill, 6-3/16, 5-15/16, 7/8, edge, 6-3/4, suisse, confirmation, exempt, read, page, grace, disburse, utilisation, household, seventh, socialist, campaign, sunday, privatisation, director-general, la, sweeping, paribas, et, lombard, eliminate, algeria, erasable, programmable, memory, unfairly, proof, justified, subscription, basically, urgent, postwar, criticism, meeting., notable, annuity, hague, goodwill, g-7, appreciate, suppose, holiday, warmer, guidance, entry, presence, gelco, kingdom, pool, realise, district, bargaining, membership, suntrust, sti, argentine, cow, default, r., c., kansa, waive, boveri, bbc, bbcz.z, carlo, e.f, hutton, banco, 7-3/4, inject, category, mixed, slowdown, semi-annual, disappointment, cope, rout, sustained, wealthy, poorest, occasion., graphic, fhlbb, two-third, depository, adequate, consent, plc., restricted, esso, educational, sallie, mae, student, 5-14, mac, frankfurt, upper, unnamed, interior, omit, exchangeable, resign, s., t., leasing, demonstrate, growth., standstill, diamond, salt, incorporate, states., presentation, reference, briefly, canron, quebec, rotterdam, undercut, upturn, strictly, already., bethlehem, inland, efficient, turnaround, mid, 1/8, neutral, mix, diagnostic, pharmaceutical, hot, unlike, brasil, cacex, orderly, sustainable, policy-making, simply, compensatory, royal, roy, jersey, joseph, undervalue, months., rome, contact, retirement, notion, semiannual, so., mid-1990, game, cruz, accordance, instruction, obvious, drexel, lambert, burnham, accomplishment, comparable, kenneth, puerto, rico, liberty, citicorp, entirely, t-bill, bidder, consensus, informally, resolution, ctyn, rd, dutch/shell, fb, quantity, jeopardize, belong, involvement, counter-productive, brighten, greenshield, toronto, slip, curtail, ussr, juice, freeze, degree, amend, trigger, shp, beverage, shamrock, 20-year, evaluation, 1-1/2, adam, detailed, argentina, foremost, bankruptcy, trap, provincial, newhall, dependency, inevitable, disincentive, synthetic, foodstuff, receipt, conjunction, facilitate, dd, tract, conoco, hydrocarbon, patient, write-off, funding, direction, mcdonnell, strict, inch, extended, miss, minus, correction, tucker, address, mandate, worst, uplift, overcome, precision, jack, identity, chicken, favor, calling, medicine, fort, determination, agreed, hefty, wish, technique, tackle, tactic, unreasonable, stripper, arctic, wildlife, refuge, judge, illegally, jay, irve, dismiss, ottawa, edmonton, lukman, couple, annum, rilwanu, industrialise, swing, stimulation, inappropriate, helmut, kohl, severely, stretch, revision, die, condemn, speed, century, adherence, hint, modify, recoverable, one-fifth, endanger, caribou, lee, superior, ncnb, maryland, rejection, maximize, turmoil, false, misleading, richfield, arc, mold, shultz, selective, confront, impossible, reasonably, bold, champion, breach, punta, del, este, auspex, jamaican, resort, chair, jamaica, senegal, papua, guinea, coat, bcf, mideast, vital, military, mountain, camp, actual, logic, aspen, individual, dan, timing, undetermined, mercantile, hardware, metric, feel, interprovincial, shall, hr, norwegian, brass, burst, thousand, metre, shell, vessel, friendly, tanker, fly, task, planned, municipal, language, telegraph, andrew, inroad, continuation, mfn, one-year, hungary, fate, missile, republican, imply, enhancement, g., expanded, massachusett, modern, optimism, analysis, sam, veto, destine, legislator, enactment, persian, supporter, critic, bombing, leftist, army, ecopetrol, estimated, pump, columbian, recipient, hide, promising, constraint, liberalize, lifting, protected, surround, venezuelan, manuel, azpurua, one-half, norway, senator, appropriation, iran-iraq, contrary, furthermore, choice, mitigate, jawboning, barney, harris, upham, upside, westpac, indicator, anza., crane, shot, austerity, disaster, anxious, divert, usually, disagreement, budgetary, useful, colleague, unusually, promise, rice, 1990s, viability, intensify, overcapacity, variable, rupture, guillermo, dehesa, spell, drastic, plenty, gill, acid, unilateral, denman, multilaterally, dangerous, path, impede, six-month, pittsburgh, rush, shield, looming, scope, obstacle, abolition, coalition, swell, copy, lay-off, struggle, generate, autumn, cftc, abandon, unresolved, bro, comprehensive, satisfactorily, cepe, plain, petrocanada, fran, permission, ample, merely, arizona, code, future., high-tech, crossroad, destocke, boee, hydraulic, medium-term, mission, cd, york-based, forma, restart, south-east, two-day, tourist, regain, fadhil, al-chalabi, sacrifice, credibility, caraca, painful, conservation, easily, reflection, rebuild, buoyant, unveil, align, insure, self-sufficiency, embassy, intense, risky, audience, dismantling, dismantle, ireland, refusal, narrowing, inevitably, export-led, hongkong, overdraft, s.korea, won, condensate, marginal, excise, 5.5p, gauge, taxpayer, voluntary, telex, guide, pertamina, contractual, understanding, commencement, crush, reschedule, hardship, desire, upwardly, norman, der, alter, severance, frank, westminster, nwbl.l, rpt, intact, unwilling, fence, mildly, pessimistic, negotiable, presidency, unity, package., oil-rich, gasoline-rich, first-half, mirror, minimal, one-quarter, barter, reluctance, kleinwort, cts/bbl, novemb, calm, nervous, subsidize, posting, phillip, wti, spin-off, disappointing, bernstein, multiple, shc, edmonton/swann, bbl, imo.a, tultex, ttx, margarine, hugely, southland, dlrs/bbl, murphy, permian, slc, citgo, age, wildcat, petro-canada, antwerp, firmly, justify, discriminatory, unp, champlin, nippon, strip, deductible, eventual, two-year, initiate, powdered, hemisphere, dupont, tran, criticise, uruguay, procurement, oversee, api, temper, benson, availability, lubricant, unprofitable, efficiency, inspire, indefinite, integral, embark, servant, toll, wrong, effectiveness, film, contractor, lucrative, wyome, airport, fruit, worse, sorely, ryan, la., moore, closure, accumulate, lag, steve, prevail, dwindle, english, player, rich, dozen, majeure, sulphuric, stoppage, hale, railroad, thought, husky, substance, hyo.to, wedge, u.s.-canada, u.s.-canadian, brian, mulroney, oecd, halve, marked, finland, fsi, nfsi, reeacquisition, precambrian, uneconomic, grease, monkey, gmhc, nov, acpt, mnst, respective, toog, option-granting, asc, kasler, kasl, un.a, angus, cbm.n, niall, fitzgerald, divergence, 50.17p, stauffer, lipton, surf, detergent, peke, discard, prejudice, generalise, gsp, print, counsellor, chen, shibiao, behaviour, out-of-date, pickup, insititute, accountant, intek, idcc, population, pharmacia, phab, st, once-off, know-how, adr, parity, lkb-produkter, intermedics-intraocular, dbkg.f, bankamerica, clash, minute, fre, trademark, agent, post-tax, op, dane, elimination, bank/canada, uncertain, guinean, lifetime, healthcare, herman, croo, re-orient, europe., introducte, problems., products., stupid, upset, mosty, suprlus, diverted, clout, fom, west., atmosphere, dramatize, headline, rostenkowski, temptation, club, d-ill., screen, plea, fairness, 1/2, fellow, stephen, career, ecgd, aged, convern, lump, at., trough, qustion, newsletter, sesame, artificially, catastrophe, evident, reluctant, luncheon, suicide, airbus, industrie, unexpected, midafternoon, unique, reshape, ccr, harold, annualize, carryover, ultimately, standpoint, certainty, timely, 30-35, saudis, jawbone, longshot, cheating, appearance, mckinley, oversell, rally., yeterray, indidate, denial, postition, subroto, canot, marion, indepedent, slack, 4-1/2, panic, sooner, jam, raymond, pancanadian, whitehall, distillate, residual, francisco-based, sponsor, patrick, leahy, d-vt., sen., melcher, d-mont., donation, pl480, concessional, bangladesh, tunisia, morocco, injury, apple, yr-ago, wellemeyer, ope, interfuel, resolved., exemption, mcdonald, non-voting, problem., pontiac, 24-month, 36-month, 48-mopnth, 60-month, equip, interst, ann, camco, specifically, ought, infe, apolonio, ruiz, ligero, four-year, fad, context, abroad., swift, korean/taiwan, fairchild, lastly, market., treat, bind, fourteen, 13-week, brown-forman, bfdb, refund, transition, soften, easing, compatible, hugo, paeman, multilateral, etienne, davignon, luyten, energy/california, curti, birr, bolster, munger, track, dreg, ed, malmgreen, marker, blend, stripp, extraction, cloud, kern, crawl, mitchell, guerard, srd, deep, gathering, simple, sudden, idaho, unfortunate, gat, woong-bae, rha, sources., parts., federally, u.s.-, briefing, low-price, 12-nation, preferential, minoru, endo, unfounded, herring, prohibit, unprocessed, salmon, herre, stiff, 3-1/2, algerian, counterpart, belkacem, nabi, ap, permament, alick, buchanan-smith, diving, buchanan, snith, brent-grade, style, britian, oil-consuming, oil-producing, hal, february., nugent, oilpatch, lawmaker, revitalize, tertiary, coherent, way., deplore, shy, fertiliser, syndicate, six-year, seven-year, mhc, dlr/bbl, wrap, cap, drag, u.s.protectionism, eec, retaliate., ec-u.s., u.s.-ec, brink, reesentment, unilaterally, deadlines., commuity, better., bypass, agreeeement, arbiter, interpret, wonder, 49-1/8, accomplish, load, financier, route, yeutter, carlos, drawdown, preparatory, petrleum, strive, faith, short-covering, quiet, dead, unbalanced, limitation, balance., honour, diversity, ht, bko, ike, kerridge, belgolux, belgo-luxembourg, bleu, half-point, broad-based, 12-member, kaputin, privileged, beneficiary, kina, exactly, undersecretary, wallis, domestic-led, supercomputer, kansai, jeopardy, fundamentally, labour, heighten, chartered, polish, poland, precise, hypothetical, blur, illusory, excuse, under-, achieving, favoured, suppression, martial, devise, offshoot, envoy, extrapolate, freely, theoretical, evaluation., illusion, misunderstanding, phenomenon, nebulous, curbing, janusz, kaczurba, pap, uncommonly, dlrs., moral, torpedoing, ice, pole, immorally, solidarity., wladyslaw, baka, partners., debt., obstruct, superpower, cooperate, anatolian, egyptian, overproduction, arabian, overprice, country-by-country, gabon, decree, gazette, interest., mike, ocean, warwick, leed, dresdner, exit, amstutz, underestimate, detect., proceeding, administer, newsprint, greatly, carroll, proportionately, georgia, rip, archer, taper, gnt, independently, prestige, financially, wilderness, premdor, ho, peninsula, staley, coke, cpl, desjardin, visa, confederation, caisses, populaires, d'economie, desjardins, unpaid, billing, designate, petroleo, pdvsa, doe, herrington, better, tap, neighbour, dollar/yen, urging, diet, populous, ratification, unofficial, safe, forbid, crumble, cautiously, absorb, craa., a/, dependence, li, petition, prospective, ferdinand, marco, now., relieve, pall, 8-1/2, mediator, picken, accrue, importance, firming, quake, pile, paralyse, society, perceive, tarrif, equatorial, equa, casey, dia, unpleasant, demonstration, occurrence, felipe, gonzalez, maximium, companion, anticipation, nice, revalue, gesture, backing, hypothesis, jurisdiction, understandably, dennis, eradicate, inhibit, legitimate, opecna, secretariat, price., biannual, noticeably, month., lifter, entail, extraordinrary, matrix, seven-state, assertion, entrant, fortune, constant, cook, carlucci, mthly, sc, pre-budget, penal, 11-3/4, drew, three-quarters, rates., 1.5798/808, 1.5650/60, 2.8900/60, 2.8720/50, re-rating, fellner, bout, bet, upheaval, harmful, pause, guess, egpc, ras, bahar, stockbroker, prudential, ward, buildup, inflate, striking, almir, fault, harbour, kit, tandem, yellow, 3/8, hurdle, 3-3/4, underproduce, correct., propuce, 75-100, refiner-buyer, free-for-all, seven-nation, twice-postponed, grades., fibre, mississippi, pearl, encounter, u.s.-european, harmony, bailey, attendance, tension, jean-claude, paye, franz-josef, feiter, heed, differentiate, disparity, profit-taking, suport, bouy, depression, rescheduling, simmon, phil, icg, compose, noir, yugoslavian, egon, padovan, wmx, safeguard, purusant, internationally, douglas, anybody, marketplace, ankara, yalim, eralp, territorial, berne, iea, cutback, norbec, leeway, 0.1-0.2, 0.2-0.3, yanbu, ngl, centrally, non-conventional, tar, processie, curtailment, refinancing, isthmus, maya, axp, incline, pbt, welfare, stone, sto, ^m, allowable, g-6, culminate, start., steward, ominous, society., illinois, evan, indefinitely, pumping, corporacion, estatal, petrolera, ecuatoriana, tremor, salado, aguarico, reventador, volcano, epicentre, seismologist, 12-point, mercalli, ecaudor, property-casualty, bush, imediately, temperton, 72-73, cox, ebc, amro, one-week, hoare, govett, run-up, glory, ian, harwood, mercury, confound, excitement, 3/4, pertain, three-months, sovereign, writer, kilometer, comparative, shake, greet, jacobson, destocking, ultimate, indefintiely, short-haul, scarce, readily, skeptic, hanke, friedburg, quotas., government-to-government, resold, anniversary, repeal, out-of-pocket, lumber, random, eve, assert, persaude, collision, pete, 7-1/8, stumble, beaufort, hinder, vacuum, algier, deploy, stablise, prices., petro-chemical, fishery, coradian, cdin, nicaragua, paraguay, intended, saskatchewan, flow-through, notification, u.n, m., glut, override, interpretation, re-export, apartheid, rationale, 24-hour, seven-day, one-month, two-month, three-, nine-months, 3-1/4, savings, fade, medium-sized, deck, consultative, iraq-turkey, landslide, adana, hurriyet, kirkuk, yumurtalik, alert, lago, agrio, balao, hook, eighth, hector, hurtado, unwillingness, sideways, 100-1/4, 5-3/4, 99-3/4, increased., fixed-rate, kassenobligation, fob, submission, taka, proper, discounted, nioc, colder, disguised, vlcc, individually, obligate, impair, whichever, advantageous, sell-out, woe, showdown, bipartisan, sept., grip, parking, contel, tumaco, desirable, lasting, japan., world-wide, anti-inflation, breakthrough, breathing, export-import, p., roxy, shape, chl, jwc, generous, loss-making, froze, abdelaziz, adequately, 2-3/4, roger, planner, throughput, have., roberto, fendt, govt, exact, deem, 6-1/2, untied, seminar, oil-dependent, expatriate, spate, doha, staunch, penalise, terribly, wealth, vat, one-for-two, fruitful, denomination, bolivar, mid-june, stopover, 9-1/2, 5-1/2, overshoot, sheikh, bin, sultan, tendency, irish, eagle, willy, clercq, mee, cyprus-based, authoritative, oil., entitlement, pan, ditch, mitsuru, uchida, waseda, memorandum, expiry, endorse, testing, outer, inherent, practical, range., scottish, flatten, transact, four-day, exports., reading, seperate, north-central, guerrilla, three-day, economical, joe, emergence, truly, boiler, stream, yukio, interchange, fledgling, depletion, violent, 50-minute, dramatic, dresser, di, ali, schlesinger, liberalise, 1980s, exploit, al-rai, al-aam, exert, genuine, nervousness, theirs, 13-member, fahd, doldrum, justification, wil, aramco, ex-partner, rearrange, piw, prince, porex, medco, containment, added., maxwell, iit, norske, stat, oljeselskap, stat.ol, statoil, haltenbanken, colony, voluntarily, peerless, softwood, countervail, bomb, quinn, dallas-based, comeback, ineffective, annoy, deserve, fulfill, 6-7/8, saddle, 1973-74, embargo, parish, displace, insistence, offical, facto, retroactive, market-related, tranche, 1987-92, oda, 28-day, 6.5p, sufficiently, ebullient, reputation, bloated, 1960s, finger, markka, 27.5p, peasant, peking, accusation, summon, suleiman, al-sabah, hisham, nazer, riyadh, architect, distortion, deeply, basix, bas, cultural, unjustified, deflect, realism, petronas, spoil, prosperity, advice, deflationary, fan, countenance, stability., abdul, rachman, ramly, 9-1/4, plough, 7-1/4, schlumberger, slb, rid, mmc, disturb, subdue, blip, encouraging, opec-led, srv, third-quarter, lasmo, billlion, trillium, transamerica, drummond, oilman, upsurge, speedy, armor, bilion, unnecessary, lpg, successor, minimize, perez, kharg, toy, coeur, d'alene, deduction, praise, issuer, bk, height, trace, pat, carney, distort, canadian-u.s., flaw, lunch, shut-in, potash, vow, downstream, corpus, christi, depositor, 20s, abundance, eager, foolish, foolishness., doing., testified, rack, amazing, japanese-made, 14th, traveler, nov., 30-year, corresponding, ivaco, 1-1/4, year., indebtedness, smooth, non-manufacturing, vice-foreign, zhou, nan, six-monthly, rotating, topple, fatal, unpopular, nakasone., flare, faction, today., ammunition, rei, shiratori, smoulder, nail, coffin, grave, hutchison, whampoa, discriminate, impatience, mede, akzo, akzo.as, signing, predatory, hit.t, kilobit, dram, oki, amortisation, compound, delicate, pain, cheung, sq, aims., ammonia, electromagnetic, categorically, rhetoric, terra, unabated, beyond., inflation., semiconducter, saver, kentucky, cntr, pearson, trustco, ceremony, welcoming, government-owned, verge, avery, escape, mlc, elk, sympathetic, discharge, elgin, captive, beneath, getty, nymex, shrug, underpin, hartford, quarter-point, mcculley, 26/27, aubrey, lanston, fomc, liro, pass., elizabeth, reiner, line., foreseeable, non-strategic, policymaker, industrialisation, viewpoint, debt-equity, six-member, g.c, goh, 5-1/16, 4-13/16, re-invest, tata, setter, bombay, enthusiastic, macsharry, punt, kearney, peop, fortnightly, engagement, 30-69, 30-124, 70-88, 125-150, 89-123, 151-173, 124-150, 174-182, 151-349, 183-349, 350-360, mtrc, von, cil, prescribed, 62-3/4, 83-1/8, 54-7/8, opertation, fos, capcity, mlotok, bunch, shaken, rough, fluctuating, post-budget, prt, henceforth, oil-related, prt-exempt, reallocation, tidy, incorrectly, ammendment, gareth, lewi, davy, mackenzie, edinburgh, osprey, arbroath, reward, bootle, safety-first, 9-11/16, simmond, electorate, tomrorow, one-point, analyse, small-print, 10-1/2, gel, pln, house-ordered, imports., pdvsa-champlin, eventuality, maturation, adapingthe, hydro-treating, difficultiesand, 80-85, ahme, wainco, wol, grandmarais, prspect, jefferson, frion, tweedel, perforation, untested, fhl, oapec, al-wattari, /oapec/opec, optimal, unviable, high-cost, full-fledged, euro-arab, allotment, anita, sar, venezuela-ecuador, fernando, alvite, remit, quito, creation, non-north, community/oapec/opec, geography, antonio, domenici, flawed, firstcorp, fcr, leather, reinveste, top-level, peaceful, al-khalifa, 13-nation, al-anba, less., opt, baht, mismatch, 10-3/8, lowering, mid-1987, dlrs/barrel, tapi, tradeable, aomi, mayor, roel, dunnen, twinned-port, drsd.f, longer-dated, routinely, hiring, platinum, rebel, handy, harman, pson.l, spr, oesterreichische, mood, saint, area., customarily, recording, well., gatt-approved, counter-reaction, threshhold, textile-state, review., bus, 20-month, neyra, earnng, coinage, nation-wide, profile, distinction, saf, essf.pa, sur, 1985-86, emhart, emh, chiefly, wrought, cenergy, crg, canterra, scotian, east-southeast, halifax, meter, lacey, mcentee, mcginley, karnosky, materialize, widerange, weave, florio, counterfeit, copyright, subversion, customs-cleared, yen/dollar, homeland, shiv, shanker, herbal, usher, balancing, newly-established, ke, stamp, new-found, underline, watchword, recklessness, dominance, explicitly, abdulaziz, al-salim, breakneck, tale, legendary, unpunished, outsized, non-tariff, octoer, high-yield, insured, surcharge, saudia, state-oil, 40-mln, micron, conviction, clear-cut, dampened, retracement, refco, connery, afterwhich, leiner, kahan, sizable, recur, automatically, pechiney, protocol, gosagroprom, vsevolod, murakhovsky, visnew, ahmed, zaki, yamani, scheduled., 13-year, over-production, measures., assemble, thrash, tihamah, abal-khail, oil-based, long-delayed, based., shipping-to-hotel, redec, fighter, taipei, lloy.l, resemble, instance, anonymous, questionnaire, carlton, ongpin, donor, failed, bank-led, libyan, crude., tripoli, inequality, covert, discretion, leon, febre, cordero, dignity, maintain., patricio, quevedo, staple, pariba, pre-finance, plight, 18-month, oil-financing, orginal, re-establishment, mid-east, renegotiate, cairo, year-old, youssri, mustapha, hosni, mubarak, salah, bassiouni, soviet-built, soviet-supplied, then-president, anwar, sadat, promised, intellectual, revolution, steering, unrealized, bonanza, simplify, legislate, mid-1984, centrally-planned, slacken, toughen, allegiance, frenzel, poeple, agreements., reluctantly, afl-cio, kirkland, president., jenkin, proponent, beset, decision-making, sovereignty, vulnerability, hut, cambridge, there., emerging., passionate, under-developed, under-employed, newfoundlander, albertan, prosperity., detial, published, trariff, ameritrust, franklin, lessening, downgrade, toned-down, r-mi., d-il., d-mo., d-ga., augusta, paolo, torino, loophole, subsidized, derivitive, eight-billion-dlr, mcdermott, mdr, sensible, subisdy, one., friends., jople, expense., disturbed, relations., aggravation, nomination, wellington, inter-agency, oil-dependency, harrington, nickle, overestimate, tantamount, syndication, osamu, oceanic, minsiter, honda, inexpensive, ingenuity, saito, lid, owen, atico, atfc, trico, tro, scurry-rainbow, strained, engere, pasta, strident, ill-advised, provocation, brinkmanship, self-centred, accommodation, tied-aid, effot, tied, intensive, 24-nation, hidden, lessor, psbr, avoidance, dual, systematic, syst, beacon, caljet, cryssen, edgington, orkin, lunday-thagard, ring-free, mock, petro-diamond, pressing, achieve., 5-6, question-and-answer, rash, quasijudicial, mechanisim, neighbor, mccain, be., mcclure, invoice, chip-maker, discouragement, 169-billion-dlr, 59-billion-dlr, matsui, novel, wanted, collaborate, bank-funded, java, wise, unsure, arifin, siregar, depreciate, inefficient, sidetrack, sepember, southerner, instil, tragedy., popularise, readjustment, negotiations., pirate, prauge, scotland, 700-acre, taupo, verging, super-computer, dawkin, bogge, protectionist., contemplative, ago., matter., baseless, saddam, hussein, over-reliance, apea, benbow, derive, oil-generated, 1992/93, undiscovered, 1980-84, non-middle, mcivor, super-giant, home-country, non-discriminatory, meare, /exxon, uncouple, uncoupling, taboo, pietsch, re-emerging, curve, accomodate, josef, koerner, ifo-institut, wan, ncso, tsomu, hata, neglect, rollback, practice., cracker, undamaged, ingolstadt, lavera, nowruz, rubble., deprive, ruler, ardeshir, month-long, lull, dresdn, bradstreet, capitalisation, donut, stifled, samaila, mamman, micro-chip, utmost, masaji, yamamoto, renege, diminishing., nipn.t, schultz, dram.o, rock-bottom, rebuttal, strange, publicize, tonka, tka, mcd, seismic, sfb, zero-point, qassem, taqi, agcny, ina, appointing, isam, abdul-rahim, al-chalaby, subhi, yassin, khadeir, abdel-jabbar, abdel-rahim, al-asadi, baath, hamza, al-zubeidi, al-zubedei, reshuffle, realisation, freedman, fumble, unionist, krapel, persuasive, jofree, exisite, adkerson, shuffle, shakeup, inoc, appointed, incompatible, cede, noncash, rotary, scale-back, overwhelm, substitution, entirely., ludicrous, immense, non-productive, rational, 'old, rrt, profit-based, deductibility, irritant, ridden, redouble, cut-rate, revitalise, barring, bitterly, negate, secondly, thirdly, collectively, davo, canada/u., concepcion, shine, quantitative, bae, 3.60/70, 3.75/85, openness, round., nt, timetable, ex-im, morton, draugen, rd.a, northermost, 240-270, 300-meter, single-leg, gravity-base, subsea, reservoir, buoy-loading, 3p, ch, nine-member, sudan, sudanese, add-need, crunch, czechoslovakia, soviet-bloc, democratic-controlled, bonker, highly-sensitive, optima, credit-card, pei-yuan, chia, mastercard, two-to-one, braddock, ones., melbourne, heavy-handed, japan/u., provident, trout, a14-8-89-3, w5m, northstar, tricentrol, vicinity, peanut, spice, tomato, puree, oil-tax, mid-continent, taxpayer., nic, scream, cerier, impediment, competiveness, doorstep, well-placed, fashionable, japan-bashing, nic-bashing, chandross, incipient, woong, chien-shien, big-ticket, balloon, wendt, overrall, koss, exorte, two-pronged, free-trade, teeth, namibia, rundown, injurious, widening, delighted, ouput, year-to-date, interest-straining, expansionist, dogmatically, baird, non-prt, annex, participator, prt-paying, kittiwake, corner, misguided, product-for-product, wrench, boomerang, andean, caf, galo, montano, parra, gil., bentsen, televise, abbey, almy, jointly-owned, deliberately, rhone-poulenc, drawback, laiohe, 140-well, 1979-81, anytime, comecon, soviet-led, non-recognition, maslen, no., zdzislaw, kuroski, questions., presented., ec-comecon, first-ever, goc, amauligak, mud, shoreline, barite, naturally, akzo-dupont, breaking, dutch-made, disputed, aramid, mnco, 20-member, thinh, channels., inducement, re-negotiating, dillard, american-caught, pollock, standby, infant, assset, comerica, s-k-i, probability, mortgage-backed, 7-3/8, amidst, dalian, txc, galaxy, fnb, frame, arbitrary, them., globalization, perspective, r.c, indexation, abdul-aziz, mana, al-oteiba, alexandria, 8-1/4, keller, government., gravity, loan-to-price, one-eighth, adjustable-rate, memotec, quarters., cnn, careful., anchorage, rospatch, cano, pessimism, naba., calender, 85-15, chase-amp, yannis, whittaker, wkr, whittak, liu, 11-1-1, fa, hwhh.hk, wonnacott, knotty, economics, univerity, coutervailing, natw, bcs.l, mdbl.l, staunchly, 8-3/4, 2004/08, 134-12/32, inexorable, delineation, newfoundland, economicly, terra-nova, hibernia, graven, flank, parex, foulke, strenuous, riase, rotberg, rah, woon, increases., pure, 5.63-65, 5.59-61, homeless, gigantic, napo, hardest-hit, pipelline, ande, brancho, corpse, bracho, lara, landslides., cayambe, editor, adjustable, dibona, unanimity, 3-mo, 6-mo, bond-equivalent, stopout, non-competitive, santana, upco, boone, heady, autobiography, sergey, frolov, amtorg, u.s.-ussr, post-detente, teach, shenzhen, strong-armed, recalcitrant, wolffe, marketeer, sneak, non-american, matt, aizawa, outfox, donovan, mmi, k.k, opens., communism, foreign-made, urgency., megabit, thorny, sia, are., stimulative, zaid, al-nahayan, nazir, viste, palestinian, 6-1/2-year-old, battlefield, 2.25p, creditanstalt-bankverein, phrase, jumardi, jukardi, hardjoko, seputro, megabank, troublesome, flagging, inflation-free, suggested., misgiving, will., libor, unacceptably, seaga, bno.to, co-head, interest-rate, ill-will, teran, tx.n, repaid, 180-day, caracas-based, rafael, velasco, point/oil, sandi, haber, sweeney, halliburton, vishnu, diversife, businesess, favorite, horde, gaspar, choosing, swarup, cabv.vi, hanne, androsch, re-confirm, disassociate, differentials., long-held, responsibly, tragic, tableland, 4-36-2-10w2, 17/64, 20/64, spacing, srb, influx, m-4, underperforme, 32nd, one-billion, near-instant, downpayment, bellwether, 10-9-7/8, significance., materialises., disquiet, politician, westminister, jordan-petrocanada, amman, nra, pciac, al-khatib, towe, 3-5, retaliation., concessions., hesitant, reasons., speaking, piracy, puchas, eia, despatch, overwhelming, democratic-sponsored, moderated, democratic-led, imec, france., advantage., jean-baptiste, doumeng, interagra, lent, propensity, regrettably, aturo, maracaibo, guayaquil, cnooc, lufeng, 13-1-1, stationery, pazzionotto, recurrent, longstanding, peterson, peckford, formula., transpire., dissociate, ability., lucky., semi, s.africa, gradin, black-ruled, front-line, anglo-dutch, p.j, hoenman, hair, decision., musk-oxen, inadquate, dispite, solv-ex, solv, up-front, mcmurray, athabasca, powerine, selm-societa, energia, priolo, 15th, 28th, 140-150, negative-netback, garrone, quirico, isab/garrone, mellili, 20-25th, siracusa, distillation, berre, l'etang, raffinage, cfr, visbreaker, bbl/day, outlook-ecopetrol, franciso, chona, samudio, arauca, narvaez, limon, hockin, clearcut, frightening, 'protectionism, balanced., assam, pre-equity, faithfully, unsellable, knock-down, legally, chronic, petrobra, suez-mediterranean, sedi, kerir, wilfred, wae, bmd, dww, soviet-w, east-west, stein, apholte, canadaina, sponsorship, receivables, calmness, reigning, minsitry, colon, bywater, lightweights., forego, antidumping, industory, closed-minister, quota., flashpoint, early., provincially, axworthy, harrassment, bumble, whatever., ming-yi, zhao, ziyang, samsung, mob.n, cmte, committess, tic, idly, studied., sector-specific, kid, non-canadian, morse, eali, foreign-based, liabilite, cmca, rediscount, 26-week, inseperable, re-negotiate, punte, ludolf, georg, wartenberg, cooling, watchfulness, moneyline, d-tex, hundre, weston, bkb, month-end, avy, 6-5/8, debt-burdened, prior-year, mariano, washington-based, mcc, al-qaba, rosemary, mcfadden, stave, u.s.-china, figure., alone., cobanco, cbco, bfd, larsen, blender, e.b.i, esquire, ee, obod, clri, cinram, o'malley, hnh, limp, hail, saviour, pace., 45-50, 30-40, fgrp, phi, all-star, novebmer, bdm, mrdn, coleco, clo, copany, clc, cabbage, handel, dahlberg, dahl, idbx, armr, readdress, yergin, cera, mizrahi, bpd., sprigg, bijan, moussavar-rahmani, torchmark, tmk, debenure, techamerica, tch, ka-shing, gsw, lana, mccall, mayf, alatenn, atng, munsingwear, mun, gti, famous, fam, authorizerd, shrortly, likeli, cct, clever, april., moves., mid-1960, 3.7495/98, 3.7500/03, khalifa, al-thani, one-twelfth, rationalise, shoulder, responsibilite, circumstance., over-producing, tanurah, ju'aymah, two-fold, jubail, ntt, ckgh.hk, 11-21, wako, regulation-free, ingvar, calrsson, carlsson, irritate, sub-cabinet, gamut, stop-over, end-week, frustrated., free-wheeling, tight-fisted, culprit, peeve, adverserial, well-thought-out, m.p, organiaation, chao-ming, export-earner, hkeh.hk, cavendish, non-electricity, reute, sdc, cronus, buildings., tue, porx, multi-step, restructurine, hsa, whittar, dofascoxinc, bertram-trojan, investcorp, benne, marrel, juster, daewoo, wimi, strob, strb, brenco, bren, mf, skii, kapok, kpk, humanistic, 15-18, k-tron, ktii, pdo, frm, duro-test, dur, internchange, isbj, 8-1/3, nesp, phcc, mcry, benguet, i.m., imsi, muo, jcb, payble, harley-davidson, hdi, cvgi, thunander, thdr, minneosta, dpcz, sigi, ziering, annal, ziere, immunological, dunkin, dunk, cccr, off-hour, debut, mckiernan, capozza, efp, trading., up-right, upri, self-confidence, post-war, crossborder, population., imposing, albertson, intec, intk, hydron, hyd, syntech, interenational, syne, cour, ltlp, wht, reit, raut, realmerica, raco, muncipal, mfm, pittway, pry, petrolite, plit, kapsis, kaya, erdem, seabe, inactive, telecredit, tcrd, lasr, life-health, pofit, shr/avg, kenca, bkne, whipple, comalco, cmac., goldendale, chip-export, usefulness, grey-market, fison, fisn.l, 24.3p, 3.95p, 3.34p, horticulture, tito, ayal, ayala, nueva, teapa, salina, lazaro, stcl.l, 15.9p, 4.5p, impute, bougainville, buva., iron-ore, argyle, unrealised, trans-shippe, communism., anti-communist, centralled, lever, ashton-tate, 25p, 575p, transponder, equitorial, inabiliuty, agreed-upon, oblitation, cross-default, earth, conteol, under-secretary, eishiro, sub-cabinet-level, antagonise, condemnation, weill, 30-123, administration., iif, horst, schulmann, orgnaization, levelling, finance., vak, zentralsparkasse, kommerzialbank, wien, hellmuth, klauh, genossenschaftliche, zentralbank, pale, oesterreichischen, sparkassen, girv.vi, haumer, erste, spar-casse-bank, mntl, bank-wilmington, no-fee, boatman, venezula, 1987-89, minneaplois, competitive., cardholder, royal/bank, tcf, ionterest, 5-7/8, upward., bank-houston, bacp, ncf, fannie, fnm, crowd, squaring, 30-273, 30-89, 274-294, 90-100, 295-344, 101-181, 345-360, 182-195, 196-274, 275-295, 296-360, 15-78, 15-81, 79-85, 82-88, 89-360, 89-174, 175-180, 181-360\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how many times article $i$ contains word $j$ using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "i, j = 40, 2\n",
    "print(data[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which class the $i$th article belongs to using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences: 2\n",
      "Class: earn\n",
      "Word: shareholder\n"
     ]
    }
   ],
   "source": [
    "print(\"Occurrences:\", data[0,10])\n",
    "print(\"Class:\", class_names[labels[0]])\n",
    "print(\"Word:\", vocabulary[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see that the 11th word appears twice in the first document, the first document belongs to the class \"earn\", and the 11th word is \"shareholder\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function randomly selects a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_indices(labels, *num_per_class):\n",
    "    \"\"\"\n",
    "    Returns randomly selected indices. It will return the specified number of indices for each class.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for cls, num in enumerate(num_per_class):\n",
    "        cls_indices = np.where(labels == cls)[0]\n",
    "        indices.extend(np.random.choice(cls_indices, size=num, replace=False))\n",
    "    return np.array(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, to get one sample from the first class, two from the second, three from the third, and four from the fourth, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Returned indices: [144 359 259 448 537 557 741 700 766 756]\n",
      "Samples:   (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t3\n",
      "  (0, 16)\t2\n",
      "  (0, 17)\t4\n",
      "  (0, 19)\t6\n",
      "  (0, 20)\t4\n",
      "  (0, 21)\t2\n",
      "  (0, 22)\t2\n",
      "  (0, 23)\t2\n",
      "  (0, 30)\t2\n",
      "  (0, 117)\t1\n",
      "  (0, 122)\t1\n",
      "  (0, 6285)\t1\n",
      "  (0, 6286)\t1\n",
      "  (0, 6287)\t1\n",
      "  (1, 5)\t5\n",
      "  (1, 13)\t1\n",
      "  (1, 23)\t15\n",
      "  (1, 40)\t1\n",
      "  (1, 42)\t3\n",
      "  (1, 60)\t1\n",
      "  (1, 79)\t1\n",
      "  (1, 91)\t1\n",
      "  (1, 104)\t1\n",
      "  :\t:\n",
      "  (7, 157)\t1\n",
      "  (7, 246)\t2\n",
      "  (7, 314)\t1\n",
      "  (7, 1953)\t1\n",
      "  (8, 5)\t1\n",
      "  (8, 13)\t1\n",
      "  (8, 98)\t1\n",
      "  (8, 285)\t1\n",
      "  (8, 332)\t2\n",
      "  (8, 340)\t2\n",
      "  (8, 356)\t1\n",
      "  (8, 554)\t1\n",
      "  (8, 814)\t1\n",
      "  (8, 984)\t2\n",
      "  (8, 1229)\t2\n",
      "  (8, 1539)\t1\n",
      "  (8, 1588)\t1\n",
      "  (8, 2565)\t1\n",
      "  (8, 2816)\t3\n",
      "  (8, 3165)\t1\n",
      "  (9, 290)\t1\n",
      "  (9, 641)\t1\n",
      "  (9, 1092)\t1\n",
      "  (9, 1183)\t1\n",
      "  (9, 1697)\t1\n",
      "Corresponding classes: [0 1 1 2 2 2 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "indices = sample_indices(labels, 1, 2, 3, 4)\n",
    "print(\"Returned indices:\", indices)\n",
    "print(\"Samples:\", data[indices])\n",
    "print(\"Corresponding classes:\", labels[indices])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. k-NN Implementation (4 Marks, Normal)\n",
    "\n",
    "Now, you will need to implement a k-NN classifier by filling the code below.\n",
    "This function should support two types of distance measures: Euclidean distance and cosine distance (defined as 1 - cosine similarity). It should take a set of training samples, a user-specified neighbour number, a distance option, and features of a set of testing samples as the input.\n",
    "It should return the predicted classes for the input set of testing samples.\n",
    "\n",
    "In order to get 4 marks, you are asked to implement the k-NN classifier from scrach without relying on any machine learning library, particularly the distance calculation. But you are allowed to research NumPy functions relating to sorting. If you decide to use existing distance implementation from libraries, e.g., `sklearn.metrics.pairwise_distances` imported as `cdist`, you can get at most 3 marks.\n",
    "\n",
    "**Your implementation must NOT make use of Python loops over individual samples or features**.\n",
    "You should use functions that operate on whole matrices, as this will be much faster than looping in Python.\n",
    "Each experiment below is expected to take no more than 2 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def most(row):\n",
    "    return np.bincount(row).argmax()\n",
    "\n",
    "def knn_classify(test_samples, training_data, training_labels, metric=\"euclidean\", k=1):\n",
    "    \"\"\"\n",
    "    Performs k-nearest neighbour classification on the provided samples,\n",
    "    given training data and the corresponding labels.\n",
    "    \n",
    "    test_samples: An m x d matrix of m samples to classify, each with d features.\n",
    "    training_data: An n x d matrix consisting of n training samples, each with d features.\n",
    "    training_labels: A vector of size n, where training_labels[i] is the label of training_data[i].\n",
    "    metric: The metric to use for calculating distances between samples.\n",
    "    k: The number of nearest neighbours to use for classification.\n",
    "    \n",
    "    Returns: A vector of size m, where out[i] is the predicted class of test_samples[i].\n",
    "    \"\"\"\n",
    "    # Calculate an m x n distance matrix.\n",
    "    if (metric == \"euclidean\"):\n",
    "        pairwise_distance = np.sqrt(np.sum(np.square(test_samples)[:,np.newaxis,:],axis=2)-2 * test_samples @ training_data.T + np.sum(np.square(training_data), axis=1))\n",
    "    elif (metric == \"cosine\"):\n",
    "        test_samples.data **= 2\n",
    "        sci_test_samples = scipy.sparse.csr_matrix(test_samples.sum(axis=1)).sqrt()\n",
    "        \n",
    "        training_data.data **= 2\n",
    "        sci_training_data = scipy.sparse.csr_matrix(training_data.sum(axis=1)).sqrt().transpose()\n",
    "        \n",
    "        numer = test_samples.sqrt()@training_data.sqrt().transpose()\n",
    "        denom = sci_test_samples@sci_training_data\n",
    "        \n",
    "        pairwise_distance = 1 - (numer/denom)\n",
    "    else:\n",
    "        print(\"Incorrect distance metric used\")\n",
    "        \n",
    "    # Sorts the distances \n",
    "    nearest_indices = pairwise_distance.argsort()[:, 0:k]\n",
    "    # Find the k nearest neighbours of each samples as an m x k matrix of indices.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Look up the classes corresponding to each index.\n",
    "    nearest_labels = training_labels[nearest_indices]\n",
    "    \n",
    "    \n",
    "    # Return the most frequent class on each row.\n",
    "    # Note: Ensure that the returned vector does not contain any empty dimensions.\n",
    "    # You may find the squeeze method useful here.\n",
    "    return np.apply_along_axis(most,1, nearest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 320)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "training_indices = sample_indices(labels, 80, 80, 80, 80)\n",
    "sarray = []\n",
    "for i in range(800):\n",
    "    sarray.append(i)\n",
    "sarray = np.array(sarray)\n",
    "test_samples = sarray[~np.in1d(sarray,training_indices).reshape(sarray.shape)]\n",
    "training_labels = labels[training_indices]\n",
    "\n",
    "training_data = data[training_indices].toarray()\n",
    "\n",
    "test_data = data[test_samples].toarray()\n",
    "#pairwise_distance = np.sqrt(np.sum(np.square(training_data)[:,np.newaxis,:],axis=2)-2 * training_data @ test_data.T + np.sum(np.square(test_data), axis=1))\n",
    "\n",
    "\n",
    "td = np.sqrt(np.sum(training_data**2,axis=1))[np.newaxis,:]\n",
    "ts = np.sqrt(np.sum(test_data**2,axis=1))[:,np.newaxis]\n",
    "similarity = np.dot(test_data, training_data.T)/(ts * td)\n",
    "pairwise_distance = 1. - similarity\n",
    "\n",
    "\n",
    "\n",
    "#pairwise_distances = -2 * test_data@training_data.T + np.sum(training_data**2,axis=1) + np.sum(test_data**2,axis=1)[:, np.newaxis]\n",
    "print(pairwise_distance.shape)\n",
    "\n",
    "sorted_indices = np.argsort(pairwise_distance, axis=1)\n",
    "\n",
    "nearest_indices = sorted_indices[: , 0:3 ]\n",
    "#print(nearest_indices)\n",
    "\n",
    "#nearest_neighbours = data[nearest_indices]\n",
    "nearest_labels = labels[nearest_indices]\n",
    "print(labels)\n",
    "for i in range(480):\n",
    "    for j in range(3):\n",
    "        print(labels[nearest_indices[i,j]])\n",
    "\n",
    "#print(nearest_labels)\n",
    "most = []\n",
    "a = nearest_labels\n",
    "for i in a:\n",
    "    counts = np.bincount(i)\n",
    "    most.append(np.argwhere(counts == np.max(counts))[-1][0])\n",
    "print(most)\n",
    "print(labels[test_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments (12 Marks in Total)\n",
    "\n",
    "Use your k-NN function to perform the following experiments.\n",
    "\n",
    "### Experiment 1 (4 Marks, Easy)\n",
    "\n",
    "Randomly select 80 articles per class for training, and use the remaining articles for testing.\n",
    "Fix a neighbour number setting as you see fit. Perform k-NN classification using the Euclidean distance and test it.\n",
    "\n",
    "Repeat this process 20 times (trials).\n",
    "Calculate the mean and standard deviation of the testing accuracies. Print out the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the accuracies is:  0.8387499999999999\n",
      "The standard deviation of the accuracies is:  0.04147560360554678\n"
     ]
    }
   ],
   "source": [
    "trials = 20\n",
    "k = 7\n",
    "metric = \"euclidean\"\n",
    "articles = np.arange(800)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for i in range(trials):\n",
    "    trainingIndices = sample_indices(labels, 80, 80, 80, 80)\n",
    "    testIndices = np.setdiff1d(articles, trainingIndices, assume_unique=True)\n",
    "    #data\n",
    "    trainingData = data[trainingIndices].toarray()\n",
    "    testData = data[testIndices].toarray()\n",
    "    #labels\n",
    "    trainingLabels = labels[trainingIndices]\n",
    "    testLabels = labels[testIndices]\n",
    "    \n",
    "    prediction = knn_classify(testData, trainingData, trainingLabels, metric, k)\n",
    "    #appends accuracies\n",
    "    accuracy.append(np.count_nonzero(prediction == testLabels)/ len(testLabels))\n",
    "#average accuracy\n",
    "mean = np.mean(accuracy)\n",
    "#standard deviation\n",
    "standard_deviation = np.std(accuracy)\n",
    "print(\"The mean of the accuracies is: \", mean)\n",
    "print(\"The standard deviation of the accuracies is: \", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same neighbour number, but use the cosine distance instead of the Euclidean distance.\n",
    "Repeat the same experiment.\n",
    "\n",
    "Print out the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the accuracies is:  0.961875\n",
      "The standard deviation of the accuracies is:  0.00733913123075356\n"
     ]
    }
   ],
   "source": [
    "trials = 20\n",
    "k = 7\n",
    "metric = \"cosine\"\n",
    "articles = np.arange(800)\n",
    "#list of the accuracies\n",
    "accuracy = []\n",
    "\n",
    "for i in range(trials):\n",
    "    trainingIndices = sample_indices(labels, 80, 80, 80, 80)\n",
    "    testIndices = np.setdiff1d(articles, trainingIndices, assume_unique=True)\n",
    "    #data\n",
    "    trainingData = data[trainingIndices]\n",
    "    testData = data[testIndices]\n",
    "    #labels\n",
    "    trainingLabels = labels[trainingIndices]\n",
    "    testLabels = labels[testIndices]\n",
    "    \n",
    "    prediction = knn_classify(testData, trainingData, trainingLabels, metric, k)\n",
    "    \n",
    "    accuracy.append(np.count_nonzero(prediction == testLabels)/ len(testLabels))\n",
    "mean = np.mean(accuracy)\n",
    "standard_deviation = np.std(accuracy)\n",
    "print(\"The mean of the accuracies is: \", mean)\n",
    "print(\"The standard deviation of the accuracies is: \", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain in your report which distance measure gives better performance and analyse the reason. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 (4 Marks, Easy)\n",
    "\n",
    "Using the distance measure that you found performs better in Experiment 1.\n",
    "\n",
    "Randomly select 80 articles per class for training, and use the remaining articles for testing. Perform k-NN classification with the neighbour number $k$ varying from 1 to 50.\n",
    "\n",
    "For each values of $k$, repeat the training process by 20 trials and record the average training error rates and standard deviation.\n",
    "\n",
    "Do the same for testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average training error rate:  [0.0, 0.027187499999999996, 0.044375, 0.0490625, 0.0528125, 0.05750000000000001, 0.06671875, 0.073125, 0.07546875000000001, 0.07953125, 0.07703125, 0.07828125, 0.07500000000000001, 0.08140625, 0.07859374999999999, 0.083125, 0.07953125, 0.08499999999999999, 0.08875, 0.08140625, 0.08625000000000001, 0.09390625, 0.0846875, 0.09171874999999999, 0.0934375, 0.08578125, 0.09625000000000002, 0.09359375, 0.09624999999999999, 0.09874999999999998, 0.09609375, 0.0940625, 0.09765625, 0.0996875, 0.09874999999999999, 0.0946875, 0.09390625, 0.09984374999999998, 0.09953125, 0.094375, 0.10531249999999999, 0.10015624999999999, 0.10109375000000001, 0.10390625, 0.09953124999999999, 0.09999999999999999, 0.10359375, 0.10234375, 0.0965625, 0.10046875000000002]\n",
      "training error standard deviation:  [0.0, 0.006782042004440846, 0.009862333648787188, 0.0074673769658428245, 0.007899515412352837, 0.008637671850678283, 0.013194570083466153, 0.01316214980540793, 0.012895122321540808, 0.008412869141232376, 0.013341773858355568, 0.013275734148720363, 0.013184389443580616, 0.011113538688802051, 0.012033279049681345, 0.011874999999999998, 0.011878083481248143, 0.014272734058336544, 0.013742895892060014, 0.018736323136824364, 0.015322063340164076, 0.01628226964177599, 0.010453580427298579, 0.017038415923656167, 0.0192104911116296, 0.014268457071018575, 0.016612542325002515, 0.016784333981052092, 0.0160139099691487, 0.017826200871189576, 0.016766870002701755, 0.015306121120323073, 0.01966206193885829, 0.01910855093276306, 0.016782151977621937, 0.018008786917779886, 0.015228564597082023, 0.014904481027110604, 0.01578898325375956, 0.014644218142324975, 0.02027881822863453, 0.015002441207600182, 0.014397909733273782, 0.012138322255876221, 0.013083080378393308, 0.012922545705084582, 0.01735078686075937, 0.01185339317189386, 0.014486658733124075, 0.01630624281333686]\n",
      "average testing error rate:  [0.07468749999999999, 0.08260416666666665, 0.07229166666666667, 0.07572916666666667, 0.07135416666666668, 0.07979166666666666, 0.08072916666666667, 0.08406250000000001, 0.08489583333333332, 0.08635416666666668, 0.08979166666666666, 0.0940625, 0.09760416666666666, 0.10364583333333333, 0.09927083333333332, 0.10500000000000001, 0.104375, 0.110625, 0.10302083333333334, 0.10687499999999998, 0.11239583333333332, 0.11947916666666665, 0.10229166666666667, 0.10916666666666668, 0.11677083333333334, 0.09968750000000001, 0.10614583333333334, 0.11729166666666666, 0.12052083333333334, 0.11520833333333336, 0.10593750000000002, 0.10895833333333334, 0.11552083333333332, 0.10427083333333334, 0.11239583333333333, 0.10812499999999999, 0.10666666666666669, 0.10177083333333334, 0.10697916666666667, 0.10260416666666665, 0.09770833333333333, 0.09895833333333333, 0.09760416666666667, 0.10197916666666666, 0.10093750000000001, 0.1003125, 0.09374999999999999, 0.10093749999999999, 0.09083333333333334, 0.10010416666666669]\n",
      "testing error standard deviation:  [0.007519505884697476, 0.013131198932948453, 0.011162856937182344, 0.011548414844326756, 0.013370310055201494, 0.013161325393405905, 0.012375683903660973, 0.014881986571205994, 0.009835341426316742, 0.01678958578917962, 0.011120005120902098, 0.017346486896166868, 0.00957597090377785, 0.018886942046321607, 0.011585937207331233, 0.01677568511599783, 0.019883558604479677, 0.01370732012466332, 0.017987686278087264, 0.018079444666373037, 0.019359032398771032, 0.01907444980639459, 0.01864437843485865, 0.01739801633009414, 0.01817969477420711, 0.01918788454193021, 0.020278818228634525, 0.02438568142031986, 0.024950254326804415, 0.02292708096698459, 0.017495969277871466, 0.021082880429918065, 0.025288912192127033, 0.017348988823399605, 0.012611912220639307, 0.017266548020827888, 0.01857090391505546, 0.019909463045245598, 0.019833016016369158, 0.01530753887885893, 0.018256229910788138, 0.015015905918576992, 0.014617148295941844, 0.021685438582785866, 0.015872689573779096, 0.01250477339414389, 0.014312970031098058, 0.015358491023788041, 0.01382555001919755, 0.015610757397633778]\n"
     ]
    }
   ],
   "source": [
    "training_error_mean = []\n",
    "training_error_sd = []\n",
    "\n",
    "testing_error_mean= []\n",
    "testing_error_sd = []\n",
    "#iterates 50 times\n",
    "for j in range(1,51):\n",
    "    k = j\n",
    "    trials = 20\n",
    "    metric = \"cosine\"\n",
    "    articles = np.arange(800)\n",
    "    # error rates\n",
    "    training_error_rate = []\n",
    "    testing_error_rate = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "        trainingIndices = sample_indices(labels, 80, 80, 80, 80)\n",
    "        testIndices = np.setdiff1d(articles, trainingIndices, assume_unique=True)\n",
    "        #data\n",
    "        trainingData = data[trainingIndices]\n",
    "        testData = data[testIndices]\n",
    "        #labels\n",
    "        trainingLabels = labels[trainingIndices]\n",
    "        testLabels = labels[testIndices]\n",
    "        \n",
    "        #training error\n",
    "        prediction = knn_classify(trainingData, trainingData, trainingLabels, metric, k)\n",
    "        training_error_rate.append(np.count_nonzero(prediction != trainingLabels)/ len(trainingLabels))\n",
    "        \n",
    "        #testing error\n",
    "        prediction = knn_classify(testData, trainingData, trainingLabels, metric, k)\n",
    "        testing_error_rate.append(np.count_nonzero(prediction != testLabels)/ len(testLabels))\n",
    "        \n",
    "    #append mean and sd of training \n",
    "    training_error_mean.append(np.mean(training_error_rate))\n",
    "    training_error_sd.append(np.std(training_error_rate))\n",
    "    \n",
    "    #append mean and sd of test\n",
    "    testing_error_mean.append(np.mean(testing_error_rate))\n",
    "    testing_error_sd.append(np.std(testing_error_rate))\n",
    "    \n",
    "print(\"average training error rate: \", training_error_mean)\n",
    "print(\"training error standard deviation: \", training_error_sd)\n",
    "print(\"average testing error rate: \", testing_error_mean)\n",
    "print(\"testing error standard deviation: \", testing_error_sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce an error bar plot showing the training error rate for each $k$ here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1,51)\n",
    "x = list(x)\n",
    "y = training_error_mean\n",
    "y_error = training_error_sd\n",
    "\n",
    "plt.errorbar(x,y,yerr=y_error,fmt='o',ecolor = 'red',color='yellow')\n",
    "\n",
    "plt.title(\"training error rate for each k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"training error rate\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce your testing error bar plot here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1,51)\n",
    "x = list(x)\n",
    "y = testing_error_mean\n",
    "y_error = testing_error_sd\n",
    "\n",
    "plt.errorbar(x,y,yerr=y_error,fmt='o',ecolor = 'red',color='yellow')\n",
    "\n",
    "plt.title(\"testing error rate for each k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"testing error rate\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember that all graphs should have axis labels and a title.**\n",
    "\n",
    "Discuss in your report the difference between the training and testing accuracies and its indication. Analyse in your report the effect of $k$ based on this experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 (4 Marks, Normal)\n",
    "\n",
    "Compare three 5-NN classifiers using cosine distance. In order to get 4 marks, you should implement the confusion matrix calculation from scrach yourself. If you decide to use existing implementation for confusion matrix calculation, you can get at most 3 marks.\n",
    "\n",
    "First, randomly select 100 articles per class and keep these as your testing samples. Set all the remaining articles as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "metric = \"cosine\"\n",
    "articles = np.arange(800)\n",
    "\n",
    "testIndices = sample_indices(labels, 100, 100, 100, 100)\n",
    "trainingIndices = np.setdiff1d(articles, testIndices, assume_unique=True)\n",
    "\n",
    "trainingData = data[trainingIndices]\n",
    "testData = data[testIndices]\n",
    "\n",
    "trainingLabels = labels[trainingIndices]\n",
    "testLabels = labels[testIndices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do the following:\n",
    "\n",
    "(1) Train the first classifier using the traning set.\n",
    "Compute the confusion matrix for the 4 classes using the testing samples.\n",
    "\n",
    "Print out the numbers of the training and testing samples belonging to each class, the $2\\times 2$ confusion matrix for each of the 4 classes, and the overall accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855\n",
      "confusion matrix for class earn:\n",
      "true positives:  96\n",
      "false positives:  17\n",
      "false negatives:  4\n",
      "true negatives:  283\n",
      "confusion matrix for class crude:\n",
      "true positives:  72\n",
      "false positives:  4\n",
      "false negatives:  28\n",
      "true negatives:  296\n",
      "confusion matrix for class trade:\n",
      "true positives:  86\n",
      "false positives:  28\n",
      "false negatives:  14\n",
      "true negatives:  272\n",
      "confusion matrix for class interest:\n",
      "true positives:  88\n",
      "false positives:  9\n",
      "false negatives:  12\n",
      "true negatives:  291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = op(self._deduped_data())\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = op(self._deduped_data())\n"
     ]
    }
   ],
   "source": [
    "prediction = knn_classify(testData, trainingData, trainingLabels, metric, k)\n",
    "accuracy = np.count_nonzero(prediction == testLabels)/ len(testLabels)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "earn_true_pos = 0\n",
    "earn_false_pos = 0\n",
    "earn_false_neg = 0\n",
    "earn_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==0 and prediction[i]==0):\n",
    "        earn_true_pos += 1\n",
    "    elif(testLabels[i]==0 and prediction[i]!=0):\n",
    "        earn_false_neg += 1\n",
    "    elif(testLabels[i]!=0 and prediction[i]==0):\n",
    "        earn_false_pos += 1\n",
    "    else:\n",
    "        earn_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class earn:\")\n",
    "print(\"true positives: \", earn_true_pos)\n",
    "print(\"false positives: \", earn_false_pos)\n",
    "print(\"false negatives: \", earn_false_neg)\n",
    "print(\"true negatives: \", earn_true_neg)\n",
    "\n",
    "crude_true_pos = 0\n",
    "crude_false_pos = 0\n",
    "crude_false_neg = 0\n",
    "crude_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==1 and prediction[i]==1):\n",
    "        crude_true_pos += 1\n",
    "    elif(testLabels[i]==1 and prediction[i]!=1):\n",
    "        crude_false_neg += 1\n",
    "    elif(testLabels[i]!=1 and prediction[i]==1):\n",
    "        crude_false_pos += 1\n",
    "    else:\n",
    "        crude_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class crude:\")\n",
    "print(\"true positives: \", crude_true_pos)\n",
    "print(\"false positives: \", crude_false_pos)\n",
    "print(\"false negatives: \", crude_false_neg)\n",
    "print(\"true negatives: \", crude_true_neg)\n",
    "\n",
    "trade_true_pos = 0\n",
    "trade_false_pos = 0\n",
    "trade_false_neg = 0\n",
    "trade_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==2 and prediction[i]==2):\n",
    "        trade_true_pos += 1\n",
    "    elif(testLabels[i]==2 and prediction[i]!=2):\n",
    "        trade_false_neg += 1\n",
    "    elif(testLabels[i]!=2 and prediction[i]==2):\n",
    "        trade_false_pos += 1\n",
    "    else:\n",
    "        trade_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class trade:\")\n",
    "print(\"true positives: \", trade_true_pos)\n",
    "print(\"false positives: \", trade_false_pos)\n",
    "print(\"false negatives: \", trade_false_neg)\n",
    "print(\"true negatives: \", trade_true_neg)\n",
    "\n",
    "interest_true_pos = 0\n",
    "interest_false_pos = 0\n",
    "interest_false_neg = 0\n",
    "interest_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==3 and prediction[i]==3):\n",
    "        interest_true_pos += 1\n",
    "    elif(testLabels[i]==3 and prediction[i]!=3):\n",
    "        interest_false_neg += 1\n",
    "    elif(testLabels[i]!=3 and prediction[i]==3):\n",
    "        interest_false_pos += 1\n",
    "    else:\n",
    "        interest_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class interest:\")\n",
    "print(\"true positives: \", interest_true_pos)\n",
    "print(\"false positives: \", interest_false_pos)\n",
    "print(\"false negatives: \", interest_false_neg)\n",
    "print(\"true negatives: \", interest_true_neg)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Randomly remove 95 training articles from class 1 (\"crude\") of the training set.\n",
    "Train the second classifier using the reduced training samples.\n",
    "Compute the confusion matrix for the 4 classes using the testing samples.\n",
    "\n",
    "Print out the numbers of the training and testing samples belonging to each class, the $2\\times 2$ confusion matrix for each of the 4 classes, and the overall accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.625\n",
      "confusion matrix for class earn:\n",
      "true positives:  71\n",
      "false positives:  31\n",
      "false negatives:  29\n",
      "true negatives:  269\n",
      "confusion matrix for class crude:\n",
      "true positives:  19\n",
      "false positives:  0\n",
      "false negatives:  81\n",
      "true negatives:  300\n",
      "confusion matrix for class trade:\n",
      "true positives:  91\n",
      "false positives:  108\n",
      "false negatives:  9\n",
      "true negatives:  192\n",
      "confusion matrix for class interest:\n",
      "true positives:  69\n",
      "false positives:  11\n",
      "false negatives:  31\n",
      "true negatives:  289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = op(self._deduped_data())\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = op(self._deduped_data())\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "crudeLabels = []\n",
    "randomCrude = []\n",
    "for i in range(len(trainingLabels)):\n",
    "    if(trainingLabels[i] == 1):\n",
    "        crudeLabels.append(trainingIndices[i])\n",
    "randomCrude = random.sample(crudeLabels, 95)\n",
    "trainingIndicesNew = np.setdiff1d(trainingIndices, randomCrude, assume_unique=True)\n",
    "\n",
    "trainingDataNew = data[trainingIndicesNew]\n",
    "\n",
    "\n",
    "trainingLabelsNew = labels[trainingIndicesNew]\n",
    "\n",
    "\n",
    "prediction = knn_classify(testData, trainingDataNew, trainingLabelsNew, metric, k)\n",
    "accuracy = np.count_nonzero(prediction == testLabels)/ len(testLabels)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "earn_true_pos = 0\n",
    "earn_false_pos = 0\n",
    "earn_false_neg = 0\n",
    "earn_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==0 and prediction[i]==0):\n",
    "        earn_true_pos += 1\n",
    "    elif(testLabels[i]==0 and prediction[i]!=0):\n",
    "        earn_false_neg += 1\n",
    "    elif(testLabels[i]!=0 and prediction[i]==0):\n",
    "        earn_false_pos += 1\n",
    "    else:\n",
    "        earn_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class earn:\")\n",
    "print(\"true positives: \", earn_true_pos)\n",
    "print(\"false positives: \", earn_false_pos)\n",
    "print(\"false negatives: \", earn_false_neg)\n",
    "print(\"true negatives: \", earn_true_neg)\n",
    "\n",
    "crude_true_pos = 0\n",
    "crude_false_pos = 0\n",
    "crude_false_neg = 0\n",
    "crude_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==1 and prediction[i]==1):\n",
    "        crude_true_pos += 1\n",
    "    elif(testLabels[i]==1 and prediction[i]!=1):\n",
    "        crude_false_neg += 1\n",
    "    elif(testLabels[i]!=1 and prediction[i]==1):\n",
    "        crude_false_pos += 1\n",
    "    else:\n",
    "        crude_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class crude:\")\n",
    "print(\"true positives: \", crude_true_pos)\n",
    "print(\"false positives: \", crude_false_pos)\n",
    "print(\"false negatives: \", crude_false_neg)\n",
    "print(\"true negatives: \", crude_true_neg)\n",
    "\n",
    "trade_true_pos = 0\n",
    "trade_false_pos = 0\n",
    "trade_false_neg = 0\n",
    "trade_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==2 and prediction[i]==2):\n",
    "        trade_true_pos += 1\n",
    "    elif(testLabels[i]==2 and prediction[i]!=2):\n",
    "        trade_false_neg += 1\n",
    "    elif(testLabels[i]!=2 and prediction[i]==2):\n",
    "        trade_false_pos += 1\n",
    "    else:\n",
    "        trade_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class trade:\")\n",
    "print(\"true positives: \", trade_true_pos)\n",
    "print(\"false positives: \", trade_false_pos)\n",
    "print(\"false negatives: \", trade_false_neg)\n",
    "print(\"true negatives: \", trade_true_neg)\n",
    "\n",
    "interest_true_pos = 0\n",
    "interest_false_pos = 0\n",
    "interest_false_neg = 0\n",
    "interest_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==3 and prediction[i]==3):\n",
    "        interest_true_pos += 1\n",
    "    elif(testLabels[i]==3 and prediction[i]!=3):\n",
    "        interest_false_neg += 1\n",
    "    elif(testLabels[i]!=3 and prediction[i]==3):\n",
    "        interest_false_pos += 1\n",
    "    else:\n",
    "        interest_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class interest:\")\n",
    "print(\"true positives: \", interest_true_pos)\n",
    "print(\"false positives: \", interest_false_pos)\n",
    "print(\"false negatives: \", interest_false_neg)\n",
    "print(\"true negatives: \", interest_true_neg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Randomly remove 95 training articles from each class, and do it for *all* the classes of the training set.\n",
    "Train the third classifier using the new training data.\n",
    "Compute the confusion matrix for the 4 classes using the testing samples.\n",
    "\n",
    "Print out the numbers of the training and testing samples belonging to each class, the $2\\times 2$ confusion matrix for each of the 4 classes, and the overall accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.385\n",
      "confusion matrix for class earn:\n",
      "true positives:  43\n",
      "false positives:  63\n",
      "false negatives:  57\n",
      "true negatives:  237\n",
      "confusion matrix for class crude:\n",
      "true positives:  19\n",
      "false positives:  19\n",
      "false negatives:  81\n",
      "true negatives:  281\n",
      "confusion matrix for class trade:\n",
      "true positives:  21\n",
      "false positives:  16\n",
      "false negatives:  79\n",
      "true negatives:  284\n",
      "confusion matrix for class interest:\n",
      "true positives:  71\n",
      "false positives:  148\n",
      "false negatives:  29\n",
      "true negatives:  152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = op(self._deduped_data())\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = op(self._deduped_data())\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "earnLabels = []\n",
    "crudeLabels = []\n",
    "tradeLabels = []\n",
    "interestLabels = []\n",
    "randomCrude = []\n",
    "randomEarn = []\n",
    "randomTrade = []\n",
    "randomInterest = []\n",
    "\n",
    "for i in range(len(trainingLabels)):\n",
    "    if(trainingLabels[i] == 0):\n",
    "        earnLabels.append(trainingIndices[i])\n",
    "randomEarn = random.sample(earnLabels, 95)\n",
    "\n",
    "for i in range(len(trainingLabels)):\n",
    "    if(trainingLabels[i] == 1):\n",
    "        crudeLabels.append(trainingIndices[i])\n",
    "randomCrude = random.sample(crudeLabels, 95)\n",
    "\n",
    "for i in range(len(trainingLabels)):\n",
    "    if(trainingLabels[i] == 2):\n",
    "        tradeLabels.append(trainingIndices[i])\n",
    "randomTrade = random.sample(tradeLabels, 95)\n",
    "\n",
    "for i in range(len(trainingLabels)):\n",
    "    if(trainingLabels[i] == 3):\n",
    "        interestLabels.append(trainingIndices[i])\n",
    "randomInterest = random.sample(interestLabels, 95)\n",
    "\n",
    "trainingIndicesNewer = np.setdiff1d(trainingIndices, randomEarn, assume_unique=True)\n",
    "trainingIndicesNewer = np.setdiff1d(trainingIndicesNewer, randomCrude, assume_unique=True)\n",
    "trainingIndicesNewer = np.setdiff1d(trainingIndicesNewer, randomTrade, assume_unique=True)\n",
    "trainingIndicesNewer = np.setdiff1d(trainingIndicesNewer, randomInterest, assume_unique=True)\n",
    "\n",
    "trainingDataNewer = data[trainingIndicesNewer]\n",
    "\n",
    "\n",
    "trainingLabelsNewer = labels[trainingIndicesNewer]\n",
    "\n",
    "\n",
    "prediction = knn_classify(testData, trainingDataNewer, trainingLabelsNewer, metric, k)\n",
    "accuracy = np.count_nonzero(prediction == testLabels)/ len(testLabels)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "earn_true_pos = 0\n",
    "earn_false_pos = 0\n",
    "earn_false_neg = 0\n",
    "earn_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==0 and prediction[i]==0):\n",
    "        earn_true_pos += 1\n",
    "    elif(testLabels[i]==0 and prediction[i]!=0):\n",
    "        earn_false_neg += 1\n",
    "    elif(testLabels[i]!=0 and prediction[i]==0):\n",
    "        earn_false_pos += 1\n",
    "    else:\n",
    "        earn_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class earn:\")\n",
    "print(\"true positives: \", earn_true_pos)\n",
    "print(\"false positives: \", earn_false_pos)\n",
    "print(\"false negatives: \", earn_false_neg)\n",
    "print(\"true negatives: \", earn_true_neg)\n",
    "\n",
    "crude_true_pos = 0\n",
    "crude_false_pos = 0\n",
    "crude_false_neg = 0\n",
    "crude_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==1 and prediction[i]==1):\n",
    "        crude_true_pos += 1\n",
    "    elif(testLabels[i]==1 and prediction[i]!=1):\n",
    "        crude_false_neg += 1\n",
    "    elif(testLabels[i]!=1 and prediction[i]==1):\n",
    "        crude_false_pos += 1\n",
    "    else:\n",
    "        crude_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class crude:\")\n",
    "print(\"true positives: \", crude_true_pos)\n",
    "print(\"false positives: \", crude_false_pos)\n",
    "print(\"false negatives: \", crude_false_neg)\n",
    "print(\"true negatives: \", crude_true_neg)\n",
    "\n",
    "trade_true_pos = 0\n",
    "trade_false_pos = 0\n",
    "trade_false_neg = 0\n",
    "trade_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==2 and prediction[i]==2):\n",
    "        trade_true_pos += 1\n",
    "    elif(testLabels[i]==2 and prediction[i]!=2):\n",
    "        trade_false_neg += 1\n",
    "    elif(testLabels[i]!=2 and prediction[i]==2):\n",
    "        trade_false_pos += 1\n",
    "    else:\n",
    "        trade_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class trade:\")\n",
    "print(\"true positives: \", trade_true_pos)\n",
    "print(\"false positives: \", trade_false_pos)\n",
    "print(\"false negatives: \", trade_false_neg)\n",
    "print(\"true negatives: \", trade_true_neg)\n",
    "\n",
    "interest_true_pos = 0\n",
    "interest_false_pos = 0\n",
    "interest_false_neg = 0\n",
    "interest_true_neg = 0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(testLabels[i]==3 and prediction[i]==3):\n",
    "        interest_true_pos += 1\n",
    "    elif(testLabels[i]==3 and prediction[i]!=3):\n",
    "        interest_false_neg += 1\n",
    "    elif(testLabels[i]!=3 and prediction[i]==3):\n",
    "        interest_false_pos += 1\n",
    "    else:\n",
    "        interest_true_neg += 1\n",
    "\n",
    "print(\"confusion matrix for class interest:\")\n",
    "print(\"true positives: \", interest_true_pos)\n",
    "print(\"false positives: \", interest_false_pos)\n",
    "print(\"false negatives: \", interest_false_neg)\n",
    "print(\"true negatives: \", interest_true_neg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the whole thing a few times. Based on the observed results, state in your report which of the three classifiers performs the worst, and explain in your report the reason."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Result Analysis (4 Marks in Total)\n",
    "\n",
    "### Analysis 1 (2 Marks, Normal)\n",
    "Choose a training-testing trial in Experiment 2 for k=1. Observe the testing error of this 1-NN, and estimate the interval where its true error lies with 90% probability. Explain in your report how you compute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval = 0.05500902654846386 ,  0.09436597345153612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testing_error_k1 = testing_error_mean[0]\n",
    "\n",
    "a = 1.64 * np.sqrt(testing_error_k1*(1-testing_error_k1)/480)\n",
    "\n",
    "print(\"interval =\", testing_error_k1-a, \", \", testing_error_k1+a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2 (2 Marks, Normal)\n",
    "The following function `Get_p_value()` is provided to obtain $p$ according to $z_p$. Use this function to perform Analysis 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell first\n",
    "\n",
    "def Get_p_value(zp):\n",
    "    return round(1 - scipy.stats.norm.sf(abs(zp))*2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to compare the output value of function Get_p_value with \n",
    "# the table provided in your lecture notes (e.g., Slide 12, Chapter3C.pdf)\n",
    "\n",
    "print('zp = 0.67, p = ', Get_p_value(0.67))\n",
    "print('zp = 1, p = ', Get_p_value(1))\n",
    "print('zp = 1.64, p = ', Get_p_value(1.64))\n",
    "print('zp = 2.58, p = ', Get_p_value(2.58))\n",
    "print()\n",
    "\n",
    "# you can alert the input zp value and re-run this cell to help you to calculate the corresponding p.\n",
    "print('p = ', Get_p_value(0.43))  \n",
    "\n",
    "\n",
    "# you can change 0.43 to any zp value you obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a training-testing trial in Experiment 2 for k=45. Observe the testing error of this 45-NN. Compare it with the 1-NN in Analysis 1. Which one has higher testing sample error? Estimate the probability that it also has higher true error. Explain your answer and how you compute it in the report.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 error:  0.07468749999999999\n",
      "k=45 error:  0.10093750000000001\n",
      "interval = 0.0783876091977076 ,  0.12348739080229243\n",
      "k=45 error is higher\n",
      "Probability:  0.925\n"
     ]
    }
   ],
   "source": [
    "testing_error_k45 = testing_error_mean[44]\n",
    "print(\"k=1 error: \", testing_error_k1)\n",
    "print(\"k=45 error: \", testing_error_k45)\n",
    "#a value\n",
    "a = 1.64 * np.sqrt(testing_error_k45*(1-testing_error_k45)/480)\n",
    "#prints the interval at 90%\n",
    "print(\"interval =\", testing_error_k45-a, \", \", testing_error_k45+a)\n",
    "\n",
    "d = np.absolute(testing_error_k45-testing_error_k1)\n",
    "#sigma\n",
    "o =np.sqrt((testing_error_k45*(1-testing_error_k45)/480)+(testing_error_k1*(1-testing_error_k1)/480))\n",
    "#zp value\n",
    "zp = d/o\n",
    "#gets the p value using zp\n",
    "p = Get_p_value(zp)\n",
    "#final probability\n",
    "c = 1 - (1-p)/2\n",
    "print(\"k=45 error is higher\")\n",
    "print(\"Probability: \",c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Selection (5 Marks, Hard)\n",
    "\n",
    "Use your k-NN function with cosine distance. Design an appropriate and complete machine learning experiment, which should include the training, hyper-parameter selection and evaluation stages. In this case, your hyperparameter will be $k$. You can choose from the random subsampling, k-fold CV and LOO approaches for hyperparameter selection. In order to get 5 marks, you should implement this from scrach without using readily implemented data-split functions provided in existing libraris. If you decide to use existing implementation on data splitting, model selection and/or evaluation, you can get at most 3 marks. Explain in the report your experiment design, data splitting strategy, and the obtained results, also justify your design from theory side with the machine leanring knowlwdge learned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lowest testing error for k is:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "testing_error_mean= []\n",
    "testing_error_sd = []\n",
    "#50 values of k\n",
    "for j in range(1,51):\n",
    "    k = j\n",
    "    trials = 20\n",
    "    metric = \"cosine\"\n",
    "    articles = np.arange(800)\n",
    "\n",
    "    testing_error_rate = []\n",
    "    #iterates for the number of trials\n",
    "    for i in range(trials):\n",
    "        trainingIndices = sample_indices(labels, 100, 100, 100, 100)\n",
    "        testIndices = np.setdiff1d(articles, trainingIndices, assume_unique=True)\n",
    "\n",
    "        trainingData = data[trainingIndices]\n",
    "        testData = data[testIndices]\n",
    "\n",
    "        trainingLabels = labels[trainingIndices]\n",
    "        testLabels = labels[testIndices]\n",
    "\n",
    "        prediction = knn_classify(testData, trainingData, trainingLabels, metric, k)\n",
    "        #calculates the test error rate\n",
    "        testing_error_rate.append(np.count_nonzero(prediction != testLabels)/ len(testLabels))\n",
    "\n",
    "    testing_error_mean.append(np.mean(testing_error_rate))\n",
    "    testing_error_sd.append(np.std(testing_error_rate))\n",
    "print(\"the lowest testing error for k is: \", testing_error_mean.index(min(testing_error_mean))+1)\n",
    "#plots an error graph\n",
    "x = np.arange(1,51)\n",
    "x = list(x)\n",
    "y = testing_error_mean\n",
    "y_error = testing_error_sd\n",
    "\n",
    "plt.errorbar(x,y,yerr=y_error,fmt='o',ecolor = 'red',color='yellow')\n",
    "\n",
    "plt.title(\"testing error rate for each k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"testing error rate\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval where its true error lies with 90% probability = 0.018825446750142406 ,  0.0451745532498576\n"
     ]
    }
   ],
   "source": [
    "testing_error_k1 = testing_error_mean[0]\n",
    "\n",
    "a = 1.64 * np.sqrt(testing_error_k1*(1-testing_error_k1)/480)\n",
    "\n",
    "print(\"interval where its true error lies with 90% probability =\", testing_error_k1-a, \", \", testing_error_k1+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
